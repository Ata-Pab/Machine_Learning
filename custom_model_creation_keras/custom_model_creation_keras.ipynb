{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Custom Model Creation with Keras\n",
        "\n",
        "This work will present the usage of model `fit()` method with custom-created models. We need to use fit() method for utilizing the training callbacks, loss function compatibility, and more. To make it, we should override the `training step function` of the Model class. This is the function that is called by fit() for `every batch of data`.\n",
        "\n",
        "The input argument data is what gets passed to fit as training data:\n",
        "\n",
        "* If you pass `Numpy arrays`, by calling fit(x, y, ...), then data will be the tuple (x, y)\n",
        "* If you pass a `tf.data.Dataset`, by calling fit(dataset, ...), then data will be what gets yielded by dataset at each batch.\n",
        "\n",
        "We compute the `loss` via `self.compute_loss()`, which wraps the loss(es) function(s) that were passed to `compile()`.\n",
        "\n",
        "We call `metric.update_state(y, y_pred)` on metrics from `self.metrics`, to update the state of the metrics that were passed in `compile()`, and we query results from self.metrics at the end to retrieve their current value.\n",
        "\n",
        "Reference: [Customizing what happens in fit()](https://www.tensorflow.org/guide/keras/customizing_what_happens_in_fit)"
      ],
      "metadata": {
        "id": "GZyl1ax2QgaE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kkEVnOyVQLHW"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomModel(tf.keras.Model):\n",
        "    def train_step(self, data):\n",
        "        x, y = data  # Data structure depends on your model and on what you pass to fit()\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            y_pred = self(x, training=True)  # Forward pass\n",
        "            # Compute Loss value that configured in 'compile()'\n",
        "            loss = self.compute_loss(y=y, y_pred=y_pred)\n",
        "\n",
        "        # Compute Gradients\n",
        "        trainable_vars = self.trainable_variables\n",
        "        gradients = tape.gradient(loss, trainable_vars)\n",
        "\n",
        "        # Update weights\n",
        "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
        "\n",
        "        # Update metrics\n",
        "        for metric in self.metrics:\n",
        "            if metric.name == 'loss':\n",
        "                metric.update_state(loss)\n",
        "            else:\n",
        "                metric.update_state(y, y_pred)\n",
        "\n",
        "        return {m.name: m.result() for m in self.metrics}"
      ],
      "metadata": {
        "id": "5rZe54pdZz5Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Construct and compile an instance of CustomModel\n",
        "inputs = keras.Input(shape=(32,))\n",
        "outputs = keras.layers.Dense(1)(inputs)\n",
        "\n",
        "model = CustomModel(inputs, outputs)\n",
        "model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"])\n",
        "\n",
        "# Just use `fit` as usual\n",
        "x = np.random.random((1000, 32))\n",
        "y = np.random.random((1000, 1))\n",
        "\n",
        "model.fit(x, y, epochs=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6n_KAFVhZDe",
        "outputId": "d9b41310-9b61-4ecb-fb16-463f015d8cab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "32/32 [==============================] - 1s 2ms/step - loss: 0.7988\n",
            "Epoch 2/3\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.3227\n",
            "Epoch 3/3\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.2154\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x78a4648cabf0>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's make a lower-level example, that only uses compile() to configure the optimizer.\n",
        "\n",
        "* We start by creating `Metric` instances to track our loss and a MAE score (in __init__()).\n",
        "* We implement a `custom train_step()` that `updates` the state of these `metrics` (by calling `pdate_state()` on them), then query them (via result()) to return their current average value, to be displayed by the progress bar and to be pass to any callback.\n",
        "\n",
        "\n",
        "**Note** that we would need to call `reset_states()` on our metrics between `each epoch`! Otherwise calling result() would return an average since the start of training, whereas we usually work with `per-epoch averages`. Thankfully, the framework can do that for us: just list any metric you want to reset in the metrics property of the model. The model will call reset_states() on any object listed here at the beginning of each fit() epoch or at the beginning of a call to evaluate()."
      ],
      "metadata": {
        "id": "ufKgVM4Mkkn0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomModel(tf.keras.Model):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.loss_tracker = keras.metrics.Mean(name='loss')\n",
        "        self.mae_metric = keras.metrics.MeanAbsoluteError()\n",
        "        # https://keras.io/api/metrics/\n",
        "\n",
        "    def train_step(self, data):\n",
        "        x, y = data  # Data structure depends on your model and on what you pass to fit()\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            y_pred = self(x, training=True)  # Forward pass\n",
        "            # Compute custom Loss value\n",
        "            # loss = self.compute_loss(y=y, y_pred=y_pred)\n",
        "            loss = keras.losses.mean_squared_error(y, y_pred)\n",
        "            # https://keras.io/api/losses/\n",
        "\n",
        "        # Compute Gradients\n",
        "        trainable_vars = self.trainable_variables\n",
        "        gradients = tape.gradient(loss, trainable_vars)\n",
        "\n",
        "        # Update weights\n",
        "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
        "\n",
        "        # Compute your custom metrics\n",
        "        self.loss_tracker.update_state(loss)\n",
        "        self.mae_metric.update_state(y, y_pred)\n",
        "        return {'loss': self.loss_tracker.result(), 'mae': self.mae_metric.result()}\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        # We list our `Metric` objects here so that `reset_states()` can be\n",
        "        # called automatically at the start of each epoch\n",
        "        # or at the start of `evaluate()`.\n",
        "        # If you don't implement this property, you have to call\n",
        "        # `reset_states()` yourself at the time of your choosing.\n",
        "        return [self.loss_tracker, self.mae_metric]"
      ],
      "metadata": {
        "id": "xD0Yo-7Yh89c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Construct an instance of CustomModel\n",
        "inputs = keras.Input(shape=(32,))\n",
        "outputs = keras.layers.Dense(1)(inputs)\n",
        "model = CustomModel(inputs, outputs)\n",
        "\n",
        "# We don't passs a loss or metrics here.\n",
        "model.compile(optimizer=\"adam\")\n",
        "\n",
        "# Just use `fit` as usual -- you can use callbacks, etc.\n",
        "x = np.random.random((1000, 32))\n",
        "y = np.random.random((1000, 1))\n",
        "model.fit(x, y, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3cLsWVMJ3vm",
        "outputId": "00fb2986-f53b-4691-d400-66d2fb361885"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "32/32 [==============================] - 1s 3ms/step - loss: 0.4256 - mae: 0.6184\n",
            "Epoch 2/5\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.2220 - mae: 0.3939\n",
            "Epoch 3/5\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.2040 - mae: 0.3655\n",
            "Epoch 4/5\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1995 - mae: 0.3522\n",
            "Epoch 5/5\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1947 - mae: 0.3536\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x78a464633dc0>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Give sample_weight & class_weight to the model\n",
        "\n",
        "If you want to support the fit() arguments `sample_weight` and `class_weight`, you'd simply do the following:\n",
        "\n",
        "* `Unpack` sample_weight from the data argument\n",
        "* Pass it to `compute_loss` & `update_state`."
      ],
      "metadata": {
        "id": "Q9vubOK_KsMB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomModel(tf.keras.Model):\n",
        "    def train_step(self, data):\n",
        "        # Unpack data\n",
        "        if len(data) == 3:\n",
        "            x, y, sample_weight = data\n",
        "        else:\n",
        "            sample_weight = None\n",
        "            x, y = data\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            y_pred = self(x, training=True)\n",
        "            # The loss function is configured in `compile()`.\n",
        "            loss = self.compute_loss(\n",
        "                y=y,\n",
        "                y_pred=y_pred,\n",
        "                sample_weight=sample_weight,\n",
        "            )\n",
        "\n",
        "        # Compute gradients\n",
        "        trainable_vars = self.trainable_variables\n",
        "        gradients = tape.gradient(loss, trainable_vars)\n",
        "\n",
        "        # Update weights\n",
        "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
        "\n",
        "        # Update the metrics.\n",
        "        # Metrics are configured in `compile()`.\n",
        "        for metric in self.metrics:\n",
        "            if metric.name == \"loss\":\n",
        "                metric.update_state(loss)\n",
        "            else:\n",
        "                metric.update_state(y, y_pred, sample_weight=sample_weight)\n",
        "\n",
        "        # Return a dict mapping metric names to current value.\n",
        "        # Note that it will include the loss (tracked in self.metrics).\n",
        "        return {m.name: m.result() for m in self.metrics}"
      ],
      "metadata": {
        "id": "zGN59HZ8J8s-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Construct and compile an instance of CustomModel\n",
        "inputs = keras.Input(shape=(32,))\n",
        "outputs = keras.layers.Dense(1)(inputs)\n",
        "\n",
        "model = CustomModel(inputs, outputs)\n",
        "model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"])\n",
        "\n",
        "# You can now use sample_weight argument\n",
        "x = np.random.random((1000, 32))\n",
        "y = np.random.random((1000, 1))\n",
        "sw = np.random.random((1000, 1))  # Sample weights\n",
        "model.fit(x, y, sample_weight=sw, epochs=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wpUEARlMO1YI",
        "outputId": "65c955f0-4430-4f50-afa5-6d70f0f8aaca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "32/32 [==============================] - 1s 2ms/step - loss: 0.8560\n",
            "Epoch 2/3\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.4002\n",
            "Epoch 3/3\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.2066\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x78a455fca080>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Providing custom Evaluation steps\n",
        "\n",
        "Apply the same steps for test_step as done for train_step."
      ],
      "metadata": {
        "id": "wfu11INqPNZc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomModel(tf.keras.Model):\n",
        "    def test_step(self, data):\n",
        "        # Unpack data\n",
        "        x, y = data\n",
        "\n",
        "        # Compute predictions\n",
        "        y_pred = self(x, training=False)\n",
        "\n",
        "        # Update the metrics tracking the loss\n",
        "        self.compute_loss(y=y, y_pred=y_pred)\n",
        "\n",
        "        # Update the metrics\n",
        "        for metric in self.metrics:\n",
        "            if metric.name != \"loss\":\n",
        "                metric.update_state(y, y_pred)\n",
        "        # Return a dict mapping metric names to current value.\n",
        "        # Note that it will include the loss (tracked in self.metrics).\n",
        "        return {m.name: m.result() for m in self.metrics}"
      ],
      "metadata": {
        "id": "C2QhxvSGO8vH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Construct an instance of CustomModel\n",
        "inputs = keras.Input(shape=(32,))\n",
        "outputs = keras.layers.Dense(1)(inputs)\n",
        "model = CustomModel(inputs, outputs)\n",
        "model.compile(loss=\"mse\", metrics=[\"mae\"])\n",
        "\n",
        "# Evaluate with our custom test_step\n",
        "x = np.random.random((1000, 32))\n",
        "y = np.random.random((1000, 1))\n",
        "model.evaluate(x, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "goHH8cDQQUGa",
        "outputId": "52436a08-3b89-49db-8d38-5a8d9f57b237"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 [==============================] - 0s 2ms/step - loss: 0.7420\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.741997480392456"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### End-to-end GAN Example"
      ],
      "metadata": {
        "id": "6T6T6CtoQYZV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![](https://camo.githubusercontent.com/c2f14b881d82a7ff68054cfc41c0152c7c5e2ba887fd62f0b8afcdfc02b77d1f/68747470733a2f2f7777772e74656e736f72666c6f772e6f72672f7475746f7269616c732f67656e657261746976652f696d616765732f67616e322e706e67)"
      ],
      "metadata": {
        "id": "YsBiYO0BgSac"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "class GAN(tf.keras.Model):\n",
        "    def __init__(self, input_shape, latent_dim):\n",
        "        super().__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self._input_shape = input_shape\n",
        "        self.discriminator = self.discriminator_model(self._input_shape)\n",
        "        self.generator = self.generator_model(self.latent_dim)\n",
        "        self.d_loss_tracker = keras.metrics.Mean(name=\"d_loss\")\n",
        "        self.g_loss_tracker = keras.metrics.Mean(name=\"g_loss\")\n",
        "\n",
        "    def call(self):\n",
        "        super().call()\n",
        "\n",
        "    def generator_model(self, latent_dim):\n",
        "        return keras.Sequential(\n",
        "        [\n",
        "            keras.Input(shape=(latent_dim,)),\n",
        "            # We want to generate 128 coefficients to reshape into a 7x7x128 map\n",
        "            layers.Dense(7 * 7 * 128),\n",
        "            layers.LeakyReLU(alpha=0.2),\n",
        "            layers.Reshape((7, 7, 128)),\n",
        "            layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
        "            layers.LeakyReLU(alpha=0.2),\n",
        "            layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
        "            layers.LeakyReLU(alpha=0.2),\n",
        "            layers.Conv2D(1, (7, 7), padding=\"same\", activation=\"sigmoid\"),\n",
        "        ],\n",
        "        name=\"generator\",\n",
        "        )\n",
        "\n",
        "    def discriminator_model(self, input_shape):\n",
        "        # Create the discriminator\n",
        "        return keras.Sequential(\n",
        "            [\n",
        "                keras.Input(shape=input_shape),\n",
        "                layers.Conv2D(64, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "                layers.LeakyReLU(alpha=0.2),\n",
        "                layers.Conv2D(128, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "                layers.LeakyReLU(alpha=0.2),\n",
        "                layers.GlobalMaxPooling2D(),\n",
        "                layers.Dense(1),\n",
        "            ],\n",
        "            name=\"discriminator\",\n",
        "        )\n",
        "\n",
        "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
        "        super().compile()\n",
        "        self.d_optimizer = d_optimizer\n",
        "        self.g_optimizer = g_optimizer\n",
        "        self.loss_fn = loss_fn\n",
        "\n",
        "    def train_step(self, real_images):\n",
        "        if isinstance(real_images, tuple):\n",
        "            real_images = real_images[0]\n",
        "        # Sample random points in the latent space\n",
        "        batch_size = tf.shape(real_images)[0]  # Get batch size\n",
        "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
        "\n",
        "        # Decode them to fake images\n",
        "        generated_images = self.generator(random_latent_vectors)\n",
        "\n",
        "        # Combine them with real images\n",
        "        combined_images = tf.concat([generated_images, real_images], axis=0)\n",
        "\n",
        "        # Assemble labels discriminating real from fake images\n",
        "        labels = tf.concat(\n",
        "            [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0\n",
        "        )\n",
        "\n",
        "        # Add random noise to the labels\n",
        "        labels += 0.05 * tf.random.uniform(tf.shape(labels))\n",
        "\n",
        "        # Train the discriminator\n",
        "        with tf.GradientTape() as tape:\n",
        "            predictions = self.discriminator(combined_images)\n",
        "            d_loss = self.loss_fn(labels, predictions)\n",
        "\n",
        "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
        "        self.d_optimizer.apply_gradients(zip(grads, self.discriminator.trainable_weights))\n",
        "\n",
        "        # Sample random points in the latent space\n",
        "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
        "\n",
        "        # Assemble labels that say \"all real images\"\n",
        "        misleading_labels = tf.zeros((batch_size, 1))\n",
        "\n",
        "        # Train the generator\n",
        "        # Do not update the weights of the discriminator\n",
        "        with tf.GradientTape() as tape:\n",
        "            predictions = self.discriminator(self.generator(random_latent_vectors))\n",
        "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
        "\n",
        "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
        "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
        "\n",
        "        # Update metrics\n",
        "        self.d_loss_tracker.update_state(d_loss)\n",
        "        self.g_loss_tracker.update_state(g_loss)\n",
        "        return {\"d_loss\": self.d_loss_tracker.result(),\n",
        "                \"g_loss\": self.g_loss_tracker.result()}"
      ],
      "metadata": {
        "id": "AfOn1zALQbN7"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_SHAPE = (28,28,1)\n",
        "LATENT_DIM = 128\n",
        "BATCH_SIZE = 64\n",
        "LEARNING_RATE = 0.0003"
      ],
      "metadata": {
        "id": "zbWrLgnLi0Ja"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load and prepare dataset"
      ],
      "metadata": {
        "id": "mjMhfnuFi2bP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "(x_train, _), (x_test, _) = keras.datasets.mnist.load_data()\n",
        "all_digits = np.concatenate([x_train, x_test])\n",
        "all_digits = all_digits.astype(\"float32\") / 255.0\n",
        "all_digits = np.reshape(all_digits, (-1, 28, 28, 1))"
      ],
      "metadata": {
        "id": "SbovzoaVQbLz"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices(all_digits)\n",
        "dataset = dataset.shuffle(buffer_size=1024).batch(BATCH_SIZE).cache().prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "_PqUsbJUi5M_"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gan = GAN(input_shape=INPUT_SHAPE, latent_dim=LATENT_DIM)\n",
        "gan.compile(\n",
        "    d_optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
        "    g_optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
        "    loss_fn=keras.losses.BinaryCrossentropy(from_logits=True)\n",
        ")"
      ],
      "metadata": {
        "id": "U99dlUG8i5K7"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gan.fit(dataset.take(100), epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TumpnRt5i5HP",
        "outputId": "ca363427-257a-495f-bbaf-88d2976be594"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "100/100 [==============================] - 6s 28ms/step - d_loss: 0.4790 - g_loss: 0.9171\n",
            "Epoch 2/5\n",
            "100/100 [==============================] - 3s 27ms/step - d_loss: 0.2372 - g_loss: 1.5498\n",
            "Epoch 3/5\n",
            "100/100 [==============================] - 3s 28ms/step - d_loss: 0.0401 - g_loss: 3.8153\n",
            "Epoch 4/5\n",
            "100/100 [==============================] - 3s 28ms/step - d_loss: 0.2817 - g_loss: 3.0760\n",
            "Epoch 5/5\n",
            "100/100 [==============================] - 3s 28ms/step - d_loss: 0.3748 - g_loss: 1.7955\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x78e283d59660>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reference\n",
        "\n",
        "https://www.tensorflow.org/guide/keras/customizing_what_happens_in_fit"
      ],
      "metadata": {
        "id": "5qvjsbeeQbfn"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2goGvgEOn50_"
      },
      "execution_count": 41,
      "outputs": []
    }
  ]
}