{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VmqPFJo2CD3C"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()"
      ],
      "metadata": {
        "id": "q5UT2MLyCWwC"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.astype('float32') / 255.\n",
        "x_test = X_test.astype('float32') / 255.\n",
        "\n",
        "X_train = X_train.reshape((len(X_train), np.prod(X_train.shape[1:]))) # np.prod: Return the product of array elements over a given axis. 60000, 28, 28 to 60000, 784\n",
        "X_test = X_test.reshape((len(X_test), np.prod(X_test.shape[1:])))\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YcXFRsX9CWtp",
        "outputId": "be5ab8bb-e711-44a9-f4aa-fa4c0f627116"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 784)\n",
            "(10000, 784)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = tf.reshape(X_train, shape=(X_train.shape[0], 28, 28))\n",
        "X_test = tf.reshape(X_test, shape=(X_test.shape[0], 28, 28))\n",
        "\n",
        "X_train = tf.expand_dims(X_train, axis=-1)\n",
        "X_test = tf.expand_dims(X_test, axis=-1)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "metadata": {
        "id": "MW6ZwERpKtHN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c944a17a-6775-4e8a-eabe-b238898d71b5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28, 1)\n",
            "(10000, 28, 28, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_SHAPE = (28,28,1)\n",
        "LATENT_DIM = 50\n",
        "# Training loop\n",
        "EPOCHS = 20\n",
        "BATCH_SIZE = 64"
      ],
      "metadata": {
        "id": "tqytQiedWN-5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoder Model\n",
        "def create_encoder_model(input_shape, latent_dim, kernel_size=3):\n",
        "    input = tf.keras.Input(shape=input_shape)\n",
        "    x = tf.keras.layers.Conv2D(32, kernel_size=kernel_size, padding=\"same\", activation=\"relu\")(input)\n",
        "    x = tf.keras.layers.Conv2D(64, kernel_size=kernel_size, strides=(2,2), activation=\"relu\", padding=\"same\")(x)\n",
        "    x = tf.keras.layers.Conv2D(128, kernel_size=kernel_size, strides=(2,2), activation=\"relu\", padding=\"same\")(x)\n",
        "    x = tf.keras.layers.Flatten()(x)\n",
        "    x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
        "    output = tf.keras.layers.Dense(latent_dim, name='output')(x)\n",
        "    return tf.keras.Model(input, output, name='encoder')\n",
        "\n",
        "encoder = create_encoder_model(input_shape=INPUT_SHAPE, latent_dim=LATENT_DIM,\n",
        "                             kernel_size=3)\n",
        "encoder.summary()"
      ],
      "metadata": {
        "id": "I8j9IBPbhTT2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65063cf4-f7a8-4c15-b750-9dc48540abdb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"encoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 28, 28, 32)        320       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 14, 14, 64)        18496     \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 7, 7, 128)         73856     \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 6272)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                401472    \n",
            "                                                                 \n",
            " output (Dense)              (None, 50)                3250      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 497394 (1.90 MB)\n",
            "Trainable params: 497394 (1.90 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Decoder Model\n",
        "def create_decoder_model(latent_dim, kernel_size=3):\n",
        "    input = tf.keras.Input(shape=(latent_dim,))\n",
        "    x = tf.keras.layers.Dense(128, activation='relu')(input)\n",
        "    x = tf.keras.layers.Dense(7 * 7 * 128, activation='relu')(x)\n",
        "    x = tf.keras.layers.Reshape((7, 7, 128))(x)\n",
        "    x = tf.keras.layers.Conv2DTranspose(32, kernel_size=kernel_size, activation='relu', strides=2, padding='same')(x)\n",
        "    x = tf.keras.layers.Conv2DTranspose(64, kernel_size=kernel_size, activation='relu', strides=2, padding='same')(x)\n",
        "    output = tf.keras.layers.Conv2DTranspose(1, kernel_size=kernel_size, activation='sigmoid', padding='same')(x)\n",
        "    return tf.keras.Model(input, output, name='decoder')\n",
        "\n",
        "decoder = create_decoder_model(latent_dim=LATENT_DIM,\n",
        "                             kernel_size=3)\n",
        "decoder.summary()"
      ],
      "metadata": {
        "id": "IIZLyEd9huV7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f27eef0-e674-46c5-bb0d-3768ff4007c7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"decoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 50)]              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               6528      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 6272)              809088    \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 7, 7, 128)         0         \n",
            "                                                                 \n",
            " conv2d_transpose (Conv2DTr  (None, 14, 14, 32)        36896     \n",
            " anspose)                                                        \n",
            "                                                                 \n",
            " conv2d_transpose_1 (Conv2D  (None, 28, 28, 64)        18496     \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " conv2d_transpose_2 (Conv2D  (None, 28, 28, 1)         577       \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 871585 (3.32 MB)\n",
            "Trainable params: 871585 (3.32 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Discriminator Model\n",
        "def create_discriminator_model(latent_dim):\n",
        "    input = tf.keras.Input(shape=(latent_dim,))\n",
        "    x = tf.keras.layers.Dense(64, activation='relu')(input)\n",
        "    x = tf.keras.layers.Dense(32, activation='relu')(input)\n",
        "    output = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
        "    return tf.keras.Model(input, output, name='discriminator')\n",
        "\n",
        "discriminator = create_discriminator_model(LATENT_DIM)\n",
        "discriminator.summary()"
      ],
      "metadata": {
        "id": "vuk9SzbshuTk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b14112a2-38fb-4845-8a4b-b19c7ffb8cac"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"discriminator\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 50)]              0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 32)                1632      \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1665 (6.50 KB)\n",
            "Trainable params: 1665 (6.50 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder = tf.keras.Sequential([\n",
        "    encoder,\n",
        "    decoder\n",
        "])\n",
        "\n",
        "autoencoder.summary()"
      ],
      "metadata": {
        "id": "wOQeTYtqlaGI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be7f23fa-7356-4ca7-da84-e11be68a65cc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " encoder (Functional)        (None, 50)                497394    \n",
            "                                                                 \n",
            " decoder (Functional)        (None, 28, 28, 1)         871585    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1368979 (5.22 MB)\n",
            "Trainable params: 1368979 (5.22 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_and_save_images(model, input_shape, latent_dim, epoch):\n",
        "  fig = plt.figure(figsize=(8, 8))\n",
        "\n",
        "  for i in range(16):\n",
        "      rnd_normal_noise = np.random.normal(0, 1, (1, latent_dim))\n",
        "      img = model.predict(rnd_normal_noise)\n",
        "      img = img.reshape((input_shape[0], input_shape[1]))\n",
        "      plt.subplot(4, 4, i+1)\n",
        "\n",
        "      #plt.imshow(img[i, :, :, 0] * 255)  # denormalize - for rgb images\n",
        "      plt.imshow(img, cmap=\"gray\")\n",
        "      plt.axis('off')   # No axis, show only image\n",
        "\n",
        "  #plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "rYM47IjPl5l0"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adversarial model\n",
        "# discriminator.trainable = False\n",
        "'''\n",
        "Setting the trainable property of the discriminator model to False\n",
        "during the training of the adversarial autoencoder is a technique\n",
        "used in adversarial training to decouple the training of the generator\n",
        "(or encoder in this case) from the discriminator. This is commonly\n",
        "done in a GAN (Generative Adversarial Network) setup. By setting\n",
        "trainable=False for the discriminator when training the generator,\n",
        "you essentially freeze the weights of the discriminator during the\n",
        "generator's backpropagation step. This ensures that the generator is\n",
        "updated based on the feedback from the discriminator at its current state,\n",
        "without changing the discriminator's ability to distinguish real and\n",
        "generated data.\n",
        "'''\n",
        "gan_input = tf.keras.Input(shape=INPUT_SHAPE)\n",
        "encoded_img = encoder(gan_input)\n",
        "validity = discriminator(encoded_img)\n",
        "gan = tf.keras.Model(gan_input, validity)"
      ],
      "metadata": {
        "id": "zYrjIgnyhuw6"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile models\n",
        "autoencoder.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "                    loss=tf.keras.losses.BinaryCrossentropy())\n",
        "discriminator.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "                      loss=tf.keras.losses.BinaryCrossentropy())\n",
        "gan.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "            loss=tf.keras.losses.BinaryCrossentropy())"
      ],
      "metadata": {
        "id": "NTf5pKIrhuzi"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def train_step(image_batch):\n",
        "    # Train Autoencoder\n",
        "    with tf.GradientTape() as ae_tape:\n",
        "        encoder.trainable = True\n",
        "        decoder.trainable = True\n",
        "\n",
        "        recons_imgs = autoencoder(image_batch, training=True)\n",
        "        ae_loss = autoencoder.loss(image_batch, recons_imgs)\n",
        "\n",
        "    ae_gradients = ae_tape.gradient(ae_loss, autoencoder.trainable_variables)\n",
        "    autoencoder.optimizer.apply_gradients(zip(ae_gradients, autoencoder.trainable_variables))\n",
        "\n",
        "    # Train discriminator\n",
        "    with tf.GradientTape() as disc_tape:\n",
        "        discriminator.trainable = True\n",
        "        latent_z = encoder(image_batch)\n",
        "        noise = np.random.normal(0, 1, (BATCH_SIZE, LATENT_DIM))\n",
        "\n",
        "        d_real_out = discriminator(latent_z, training=True)\n",
        "        d_fake_out = discriminator(noise, training=True)\n",
        "\n",
        "        d_loss_real = discriminator.loss(np.zeros((BATCH_SIZE, 1)), d_real_out)\n",
        "        d_loss_fake  = discriminator.loss(np.ones((BATCH_SIZE, 1)), d_fake_out)\n",
        "        d_loss = 0.5 * tf.reduce_sum(tf.add(d_loss_real, d_loss_fake))\n",
        "\n",
        "    disc_gradients = disc_tape.gradient(d_loss, discriminator.trainable_variables)\n",
        "    discriminator.optimizer.apply_gradients(zip(disc_gradients, discriminator.trainable_variables))\n",
        "\n",
        "    # Train GAN\n",
        "    with tf.GradientTape() as gan_tape:\n",
        "        encoder.trainable = True\n",
        "        discriminator.trainable = False\n",
        "\n",
        "        g_real_out = gan(image_batch, training=True)\n",
        "        g_loss = gan.loss(np.ones((BATCH_SIZE, 1)), g_real_out)\n",
        "\n",
        "    gan_gradients = gan_tape.gradient(g_loss, gan.trainable_variables)\n",
        "    gan.optimizer.apply_gradients(zip(gan_gradients, gan.trainable_variables))\n",
        "\n",
        "    return ae_loss, d_loss, g_loss"
      ],
      "metadata": {
        "id": "ZZgMINQcqBDs"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython import display\n",
        "\n",
        "ae_loss_hist = []\n",
        "d_loss_hist = []\n",
        "g_loss_hist = []\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    for _ in range(X_train.shape[0] // BATCH_SIZE):\n",
        "        idx = np.random.randint(0, X_train.shape[0], BATCH_SIZE)\n",
        "        idx_tensor = tf.constant(idx, dtype=tf.int32)\n",
        "        #real_imgs = X_train[idx]\n",
        "        real_imgs = tf.gather(X_train, idx_tensor)  # tf.gather is used to gather\n",
        "        # elements from the tensor based on the indices provided in idx_tensor.\n",
        "\n",
        "        ae_loss, d_loss, g_loss = train_step(real_imgs)\n",
        "\n",
        "    ae_loss_hist.append(ae_loss)\n",
        "    d_loss_hist.append(d_loss)\n",
        "    g_loss_hist.append(g_loss)\n",
        "\n",
        "    print(f\"ae_loss: {tf.reduce_mean(ae_loss).numpy()},  disc_loss: {tf.reduce_mean(d_loss).numpy()},  adversarial_loss: {tf.reduce_mean(g_loss).numpy()}\")\n",
        "    print (\"Reconstruction Loss:\", autoencoder.evaluate(X_train, X_train, verbose=0))\n",
        "    print (\"Adverserial Loss:\", gan.evaluate(X_train, np.ones(len(X_train)), verbose=0))\n",
        "\n",
        "    display.clear_output(wait=True)\n",
        "    generate_and_save_images(decoder, input_shape=INPUT_SHAPE, latent_dim=LATENT_DIM, epoch=epoch)"
      ],
      "metadata": {
        "id": "4vOV2pNOqcBv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alternative way to train AAE model"
      ],
      "metadata": {
        "id": "8g1Utexl2l4Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "from IPython import display\n",
        "\n",
        "# Reference: https://www.kaggle.com/code/ankasor/adversarial-autoencoding-with-keras\n",
        "for epoch in range(EPOCHS):\n",
        "    for _ in range(X_train.shape[0] // BATCH_SIZE):\n",
        "        #idx = tf.random.uniform(\n",
        "        #      shape=(BATCH_SIZE,),\n",
        "        #      minval=0,\n",
        "        #      maxval=X_train.shape[0],\n",
        "        #      dtype=tf.dtypes.int32,\n",
        "        #      seed=4,\n",
        "        #)\n",
        "        autoencoder.trainable = True\n",
        "        encoder.trainable = True\n",
        "        decoder.trainable = True\n",
        "\n",
        "        # Train Autoencoder\n",
        "        idx = np.random.randint(0, X_train.shape[0], BATCH_SIZE)\n",
        "        idx_tensor = tf.constant(idx, dtype=tf.int32)\n",
        "        #real_imgs = X_train[idx]\n",
        "        real_imgs = tf.gather(X_train, idx_tensor)  # tf.gather is used to gather\n",
        "        # elements from the tensor based on the indices provided in idx_tensor.\n",
        "\n",
        "        ae_loss = autoencoder.train_on_batch(real_imgs, real_imgs)\n",
        "\n",
        "        # Train discriminator\n",
        "        discriminator.trainable = True\n",
        "        latent_z = encoder.predict(real_imgs)\n",
        "\n",
        "        noise = np.random.normal(0, 1, (BATCH_SIZE, LATENT_DIM))\n",
        "\n",
        "        discriminator_input_x = np.concatenate([latent_z, noise])\n",
        "        discriminator_input_y = np.concatenate([np.zeros(BATCH_SIZE),\n",
        "                                                np.ones(BATCH_SIZE)])\n",
        "\n",
        "        d_loss = discriminator.train_on_batch(discriminator_input_x, discriminator_input_y)\n",
        "        # OR\n",
        "        # d_loss_real = discriminator.train_on_batch(latent_z, np.ones((BATCH_SIZE, 1)))\n",
        "        # d_loss_fake = discriminator.train_on_batch(noise, np.zeros((BATCH_SIZE, 1)))\n",
        "        # d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "        # print(f\"Discriminator Loss: {d_loss}\"\")\n",
        "\n",
        "        # Train GAN\n",
        "        gan.trainable = True\n",
        "        encoder.trainable = True\n",
        "        discriminator.trainable = False\n",
        "\n",
        "        g_loss = gan.train_on_batch(real_imgs, np.ones(BATCH_SIZE))\n",
        "        # g_loss = gan.train_on_batch(real_imgs, np.ones(BATCH_SIZE))\n",
        "        # print(f\"Adversarial Loss: {g_loss}\"\")\n",
        "\n",
        "    print (\"Reconstruction Loss:\", autoencoder.evaluate(X_train, X_train, verbose=0))\n",
        "    print (\"Adverserial Loss:\", gan.evaluate(X_train, np.ones(len(X_train)), verbose=0))\n",
        "\n",
        "    display.clear_output(wait=True)\n",
        "    generate_and_save_images(decoder, input_shape=INPUT_SHAPE, latent_dim=LATENT_DIM, epoch=epoch)\n",
        "'''"
      ],
      "metadata": {
        "id": "6jx_5RAHoKdv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "508ec7b8-056c-4cb1-dd9c-9e849b3fa5c0"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nfrom IPython import display\\n\\n# Reference: https://www.kaggle.com/code/ankasor/adversarial-autoencoding-with-keras\\nfor epoch in range(EPOCHS):\\n    for _ in range(X_train.shape[0] // BATCH_SIZE):\\n        #idx = tf.random.uniform(\\n        #      shape=(BATCH_SIZE,),\\n        #      minval=0,\\n        #      maxval=X_train.shape[0],\\n        #      dtype=tf.dtypes.int32,\\n        #      seed=4,\\n        #)\\n        autoencoder.trainable = True\\n        encoder.trainable = True\\n        decoder.trainable = True\\n\\n        # Train Autoencoder\\n        idx = np.random.randint(0, X_train.shape[0], BATCH_SIZE)\\n        idx_tensor = tf.constant(idx, dtype=tf.int32)\\n        #real_imgs = X_train[idx]\\n        real_imgs = tf.gather(X_train, idx_tensor)  # tf.gather is used to gather\\n        # elements from the tensor based on the indices provided in idx_tensor.\\n\\n        ae_loss = autoencoder.train_on_batch(real_imgs, real_imgs)\\n\\n        # Train discriminator\\n        discriminator.trainable = True\\n        latent_z = encoder.predict(real_imgs)\\n\\n        noise = np.random.normal(0, 1, (BATCH_SIZE, LATENT_DIM))\\n\\n        discriminator_input_x = np.concatenate([latent_z, noise])\\n        discriminator_input_y = np.concatenate([np.zeros(BATCH_SIZE), \\n                                                np.ones(BATCH_SIZE)])\\n\\n        d_loss = discriminator.train_on_batch(discriminator_input_x, discriminator_input_y)\\n        # OR\\n        # d_loss_real = discriminator.train_on_batch(latent_z, np.ones((BATCH_SIZE, 1)))\\n        # d_loss_fake = discriminator.train_on_batch(noise, np.zeros((BATCH_SIZE, 1)))\\n        # d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\\n        # print(f\"Discriminator Loss: {d_loss}\"\")\\n        \\n        # Train GAN\\n        gan.trainable = True\\n        encoder.trainable = True\\n        discriminator.trainable = False\\n\\n        g_loss = gan.train_on_batch(real_imgs, np.ones(BATCH_SIZE))\\n        # g_loss = gan.train_on_batch(real_imgs, np.ones(BATCH_SIZE))\\n        # print(f\"Adversarial Loss: {g_loss}\"\")\\n\\n    print (\"Reconstruction Loss:\", autoencoder.evaluate(X_train, X_train, verbose=0))\\n    print (\"Adverserial Loss:\", gan.evaluate(X_train, np.ones(len(X_train)), verbose=0))\\n    \\n    display.clear_output(wait=True)\\n    generate_and_save_images(decoder, input_shape=INPUT_SHAPE, latent_dim=LATENT_DIM, epoch=epoch)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    }
  ]
}