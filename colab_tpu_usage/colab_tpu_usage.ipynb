{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Tensor Processing Units (TPUs) Usage in Google Colab\n",
        "\n",
        "Reference: [Use TPUs - TensorFlow](https://www.tensorflow.org/guide/tpu#:~:text=and%20Cloud%20TPU.-,Setup,type%20%3E%20Hardware%20accelerator%20%3E%20TPU.)"
      ],
      "metadata": {
        "id": "dJgl-1DrnTtG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pGMzWeZOm6I4"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import os\n",
        "import tensorflow_datasets as tfds"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TPU initialization\n",
        "\n",
        "TPUs are typically Cloud TPU workers, which are different from the local process running the user's Python program. Thus, you need to do some initialization work to connect to the remote cluster and initialize the TPUs.\n",
        "\n",
        "`tf.distribute.cluster_resolver.TPUClusterResolver` is a special address just for Colab."
      ],
      "metadata": {
        "id": "NkGMpzASnLjI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "\n",
        "# This is the TPU initialization code that has to be at the beginning.\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "print(\"All devices: \", tf.config.list_logical_devices('TPU'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "in7tYLP0nCse",
        "outputId": "1615a273-1d67-4349-f9d0-973aaafc44bc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All devices:  [LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:0', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:1', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:2', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:3', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:4', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:5', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:6', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:7', device_type='TPU')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After the TPU is initialized, you can use manual device placement to place the computation on a single TPU device:"
      ],
      "metadata": {
        "id": "GCceXWUon_AA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
        "b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
        "\n",
        "with tf.device('/TPU:0'):\n",
        "  c = tf.matmul(a, b)\n",
        "\n",
        "print(\"c device: \", c.device)\n",
        "print(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWKerKsLnCp1",
        "outputId": "d916a712-ee98-446c-8a16-d4e35b21ce91"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "c device:  /job:worker/replica:0/task:0/device:TPU:0\n",
            "tf.Tensor(\n",
            "[[22. 28.]\n",
            " [49. 64.]], shape=(2, 2), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Distribution strategies\n",
        "\n",
        "Usually, you run your model on multiple TPUs in a `data-parallel` way. To distribute your model on multiple TPUs (as well as multiple GPUs or multiple machines), TensorFlow offers the `tf.distribute.Strategy` API. You can replace your distribution strategy and the model will run on any given (TPU) device.\n",
        "\n",
        "Using the `tf.distribute.TPUStrategy` option implements `synchronous distributed training`. TPUs provide their own implementation of efficient all-reduce and other collective operations across multiple TPU cores, which are used in TPUStrategy.\n",
        "\n",
        "To demonstrate this, create a tf.distribute.TPUStrategy object:"
      ],
      "metadata": {
        "id": "f4KzwmEJoIQG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "strategy = tf.distribute.TPUStrategy(resolver)"
      ],
      "metadata": {
        "id": "XzAFOZApnCnT"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To replicate a computation so it can run in all TPU cores, you can pass it into the `Strategy.run` API. Below is an example that shows all cores `receiving` the `same inputs (a, b)` and performing matrix multiplication on each core independently. The outputs will be the values from all the replicas."
      ],
      "metadata": {
        "id": "Tgk7XM01ozJk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def matmul_fn(x, y):\n",
        "  z = tf.matmul(x, y)\n",
        "  return z\n",
        "\n",
        "z = strategy.run(matmul_fn, args=(a, b))\n",
        "print(z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4BuGi0BnCkn",
        "outputId": "369d7e7c-8578-47cd-a7ee-351edef50345"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PerReplica:{\n",
            "  0: tf.Tensor(\n",
            "[[22. 28.]\n",
            " [49. 64.]], shape=(2, 2), dtype=float32),\n",
            "  1: tf.Tensor(\n",
            "[[22. 28.]\n",
            " [49. 64.]], shape=(2, 2), dtype=float32),\n",
            "  2: tf.Tensor(\n",
            "[[22. 28.]\n",
            " [49. 64.]], shape=(2, 2), dtype=float32),\n",
            "  3: tf.Tensor(\n",
            "[[22. 28.]\n",
            " [49. 64.]], shape=(2, 2), dtype=float32),\n",
            "  4: tf.Tensor(\n",
            "[[22. 28.]\n",
            " [49. 64.]], shape=(2, 2), dtype=float32),\n",
            "  5: tf.Tensor(\n",
            "[[22. 28.]\n",
            " [49. 64.]], shape=(2, 2), dtype=float32),\n",
            "  6: tf.Tensor(\n",
            "[[22. 28.]\n",
            " [49. 64.]], shape=(2, 2), dtype=float32),\n",
            "  7: tf.Tensor(\n",
            "[[22. 28.]\n",
            " [49. 64.]], shape=(2, 2), dtype=float32)\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classification on TPUs\n",
        "\n",
        "### Define a Model\n",
        "\n",
        "Dataset: MNIST\n",
        "\n",
        "Model: Convolutional Neural Network"
      ],
      "metadata": {
        "id": "KDWRv0wNpRtI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_cnn_model():\n",
        "  model= tf.keras.Sequential(\n",
        "      [tf.keras.layers.Conv2D(256, 3, activation='relu', input_shape=(28, 28, 1)),\n",
        "       tf.keras.layers.Conv2D(256, 3, activation='relu'),\n",
        "       tf.keras.layers.Flatten(),\n",
        "       tf.keras.layers.Dense(256, activation='relu'),\n",
        "       tf.keras.layers.Dense(128, activation='relu'),\n",
        "       tf.keras.layers.Dense(10)\n",
        "    ])\n",
        "\n",
        "  model.summary()\n",
        "  return model"
      ],
      "metadata": {
        "id": "vuyYgSAonCiF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Dataset\n",
        "\n",
        "Efficient use of the `tf.data.Dataset` API is critical when using a Cloud TPU. If you are using TPU Nodes, you need to `store all data files` read by the TensorFlow Dataset in `Google Cloud Storage (GCS) buckets`. If you are using TPU VMs, you can store data wherever you like.\n",
        "\n",
        "For most use cases, it is recommended to `convert` your data into the `TFRecord` format and use a `tf.data.TFRecordDataset` to read it. You can `load entire small datasets` into memory using `tf.data.Dataset.cache`.\n",
        "\n",
        "As shown in the code below, you should use the Tensorflow Datasets tfds.load module to get a copy of the MNIST training and test data. Note that `try_gcs` is specified to use a copy that is available in a public `GCS bucket`. If you don't specify this, the TPU will not be able to access the downloaded data."
      ],
      "metadata": {
        "id": "uRLAZL3gpw3J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dataset(batch_size, is_training=True):\n",
        "  split = 'train' if is_training else 'test'\n",
        "  dataset, info = tfds.load(name='mnist', split=split, with_info=True,\n",
        "                            as_supervised=True, try_gcs=True)\n",
        "\n",
        "  # Normalize the input data.\n",
        "  def scale(image, label):\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    image /= 255.0\n",
        "    return image, label\n",
        "\n",
        "  dataset = dataset.map(scale)\n",
        "\n",
        "  # Only shuffle and repeat the dataset in training. The advantage of having an\n",
        "  # infinite dataset for training is to avoid the potential last partial batch\n",
        "  # in each epoch, so that you don't need to think about scaling the gradients\n",
        "  # based on the actual batch size.\n",
        "  if is_training:\n",
        "    dataset = dataset.shuffle(10000)\n",
        "    dataset = dataset.repeat()\n",
        "\n",
        "  dataset = dataset.batch(batch_size)\n",
        "\n",
        "  return dataset"
      ],
      "metadata": {
        "id": "UwTHcNINpwFX"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train the Model"
      ],
      "metadata": {
        "id": "4s3CXvZzrdjS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 200\n",
        "steps_per_epoch = 60000 // batch_size\n",
        "validation_steps = 10000 // batch_size"
      ],
      "metadata": {
        "id": "mLSP7EOQWJn_"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "  model = get_cnn_model()\n",
        "  model.compile(optimizer='adam',\n",
        "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                metrics=['sparse_categorical_accuracy'])"
      ],
      "metadata": {
        "id": "9bHvz4CNWNg-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = get_dataset(batch_size, is_training=True)\n",
        "test_dataset = get_dataset(batch_size, is_training=False)"
      ],
      "metadata": {
        "id": "ivfqyxeKWQVD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_dataset, epochs=5,\n",
        "          steps_per_epoch=steps_per_epoch,\n",
        "          validation_data=test_dataset,\n",
        "          validation_steps=validation_steps)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HV4u9hH_rcFg",
        "outputId": "dca2b6c6-320f-435b-c089-67cb3605e39b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 26, 26, 256)       2560      \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 24, 24, 256)       590080    \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 147456)            0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               37748992  \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 38,375,818\n",
            "Trainable params: 38,375,818\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "300/300 [==============================] - 23s 44ms/step - loss: 0.1321 - sparse_categorical_accuracy: 0.9603 - val_loss: 0.0494 - val_sparse_categorical_accuracy: 0.9843\n",
            "Epoch 2/5\n",
            "300/300 [==============================] - 16s 54ms/step - loss: 0.0316 - sparse_categorical_accuracy: 0.9901 - val_loss: 0.0447 - val_sparse_categorical_accuracy: 0.9864\n",
            "Epoch 3/5\n",
            "300/300 [==============================] - 15s 50ms/step - loss: 0.0199 - sparse_categorical_accuracy: 0.9937 - val_loss: 0.0423 - val_sparse_categorical_accuracy: 0.9866\n",
            "Epoch 4/5\n",
            "300/300 [==============================] - 14s 48ms/step - loss: 0.0121 - sparse_categorical_accuracy: 0.9959 - val_loss: 0.0442 - val_sparse_categorical_accuracy: 0.9881\n",
            "Epoch 5/5\n",
            "300/300 [==============================] - 12s 39ms/step - loss: 0.0092 - sparse_categorical_accuracy: 0.9967 - val_loss: 0.0431 - val_sparse_categorical_accuracy: 0.9887\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x78c8dc2642e0>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To `reduce` Python overhead and `maximize` the `performance` of your TPU, pass in the `steps_per_execution` argument to Keras Model.compile. In this example, it increases throughput by about `50%`.\n",
        "\n",
        "**steps_per_execution**: Int. The `number of batches` to run `during each tf.function call`. Running multiple batches inside a single tf.function call can greatly `improve performance` on TPUs or small models with a large Python overhead. At most, one full epoch will be run each execution. If a number larger than the size of the epoch is passed, the execution will be truncated to the size of the epoch. Note that if steps_per_execution is set to N, `Callback.on_batch_begin` and `Callback.on_batch_end` methods will `only be called` every `N batches` (i.e. before/after each tf.function execution). Defaults to **1**."
      ],
      "metadata": {
        "id": "Z2LZYwY1r_hd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "  model = get_cnn_model()\n",
        "  model.compile(optimizer='adam',\n",
        "                # Anything between 2 and `steps_per_epoch` could help here.\n",
        "                steps_per_execution = 50,\n",
        "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                metrics=['sparse_categorical_accuracy'])"
      ],
      "metadata": {
        "id": "aGc7RulzWUta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_dataset,\n",
        "          epochs=5,\n",
        "          steps_per_epoch=steps_per_epoch,\n",
        "          validation_data=test_dataset,\n",
        "          validation_steps=validation_steps)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "biPp_yaYrx6y",
        "outputId": "e28caa04-9d8a-4cc7-fe14-2aa405c8e9d4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_2 (Conv2D)           (None, 26, 26, 256)       2560      \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 24, 24, 256)       590080    \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 147456)            0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 256)               37748992  \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 38,375,818\n",
            "Trainable params: 38,375,818\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "300/300 [==============================] - 25s 83ms/step - loss: 0.1323 - sparse_categorical_accuracy: 0.9581 - val_loss: 0.0379 - val_sparse_categorical_accuracy: 0.9885\n",
            "Epoch 2/5\n",
            "300/300 [==============================] - 5s 18ms/step - loss: 0.0341 - sparse_categorical_accuracy: 0.9893 - val_loss: 0.0349 - val_sparse_categorical_accuracy: 0.9884\n",
            "Epoch 3/5\n",
            "300/300 [==============================] - 4s 14ms/step - loss: 0.0188 - sparse_categorical_accuracy: 0.9938 - val_loss: 0.0349 - val_sparse_categorical_accuracy: 0.9900\n",
            "Epoch 4/5\n",
            "300/300 [==============================] - 5s 16ms/step - loss: 0.0121 - sparse_categorical_accuracy: 0.9960 - val_loss: 0.0376 - val_sparse_categorical_accuracy: 0.9889\n",
            "Epoch 5/5\n",
            "300/300 [==============================] - 4s 15ms/step - loss: 0.0126 - sparse_categorical_accuracy: 0.9959 - val_loss: 0.0472 - val_sparse_categorical_accuracy: 0.9861\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x78c8dc3f4880>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training the model using a Custom Training loop\n",
        "\n",
        "You can also create and train your model using `tf.function` and `tf.distribute` APIs directly. You can use the `Strategy.experimental_distribute_datasets_from_function` API to distribute the `tf.data.Dataset` given a dataset function. Note that in the example below the batch size passed into the Dataset is the per-replica batch size instead of the global batch size."
      ],
      "metadata": {
        "id": "3AnADjRPs-xa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Number of parallel TPUs: {strategy.num_replicas_in_sync}, Batch size: {batch_size}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZvl2x58SvSR",
        "outputId": "fb1a6c0e-232f-4687-972b-83a4ad671a03"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parallel TPUs: 8, Batch size: 200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Process batches as much as per_replica_batch_size per TPU\n",
        "per_replica_batch_size = batch_size // strategy.num_replicas_in_sync"
      ],
      "metadata": {
        "id": "YB-gfFH5Syi5"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "    model = get_cnn_model()\n",
        "    optimizer = tf.keras.optimizers.Adam()\n",
        "    training_loss = tf.keras.metrics.Mean('training_loss', dtype=tf.float32)\n",
        "    training_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
        "      'training_accuracy', dtype=tf.float32)\n",
        "\n",
        "    # Calculate per replica batch size, and distribute the `tf.data.Dataset`s\n",
        "    # on each TPU worker.\n",
        "    per_replica_batch_size = batch_size // strategy.num_replicas_in_sync\n",
        "\n",
        "    train_dataset = strategy.distribute_datasets_from_function(\n",
        "        lambda _: get_dataset(per_replica_batch_size, is_training=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bBgxb-dsydD",
        "outputId": "8584789b-e310-4393-9727-c149687908f7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_6 (Conv2D)           (None, 26, 26, 256)       2560      \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 24, 24, 256)       590080    \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 147456)            0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 256)               37748992  \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 38,375,818\n",
            "Trainable params: 38,375,818\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def train_step(iterator):\n",
        "    \"\"\"The step function for one training step.\"\"\"\n",
        "    def step_fn(inputs):\n",
        "        \"\"\"The computation to run on each TPU device.\"\"\"\n",
        "        images, labels = inputs\n",
        "        with tf.GradientTape() as tape:\n",
        "            logits = model(images, training=True)\n",
        "            loss = tf.keras.losses.sparse_categorical_crossentropy(\n",
        "                labels, logits, from_logits=True\n",
        "            )\n",
        "            loss = tf.nn.compute_average_loss(loss, global_batch_size=batch_size)\n",
        "            grads = tape.gradient(loss, model.trainable_variables)\n",
        "            optimizer.apply_gradients(list(zip(grads, model.trainable_variables)))\n",
        "\n",
        "            training_loss.update_state(loss*strategy.num_replicas_in_sync)\n",
        "            training_accuracy.update_state(labels, logits)\n",
        "\n",
        "    strategy.run(step_fn, args=(next(iterator),))"
      ],
      "metadata": {
        "id": "39VdViDvTiwU"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "steps_per_eval = 10000 // batch_size"
      ],
      "metadata": {
        "id": "5zyIqh-8V0q9"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_iterator = iter(train_dataset)\n",
        "\n",
        "for epoch in range(5):\n",
        "    print('Epoch: {}/5'.format(epoch))\n",
        "\n",
        "    for step in range(steps_per_epoch):  # 60000 // batch_size\n",
        "        train_step(train_iterator)\n",
        "\n",
        "    print('Current step: {}, training loss: {}, accuracy: {}%'.format(\n",
        "      optimizer.iterations.numpy(),\n",
        "      round(float(training_loss.result()), 4),\n",
        "      round(float(training_accuracy.result()) * 100, 2)))\n",
        "\n",
        "    training_loss.reset_states()\n",
        "    training_accuracy.reset_states()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQ57DN26Vxg5",
        "outputId": "8c709d34-29c2-4129-a330-9200ef7c303c"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0/5\n",
            "Current step: 1829, training loss: 0.0085, accuracy: 99.69%\n",
            "Epoch: 1/5\n",
            "Current step: 2129, training loss: 0.0078, accuracy: 99.75%\n",
            "Epoch: 2/5\n",
            "Current step: 2429, training loss: 0.0059, accuracy: 99.8%\n",
            "Epoch: 3/5\n",
            "Current step: 2729, training loss: 0.0052, accuracy: 99.81%\n",
            "Epoch: 4/5\n",
            "Current step: 3029, training loss: 0.005, accuracy: 99.84%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Improving performance with multiple steps inside tf.function\n",
        "\n",
        "By running multiple steps within a tf.function, the performance can be improved. This is achieved by wrapping the `Strategy.run` call with a `tf.range` inside `tf.function`, and AutoGraph will convert it to a `tf.while_loop` on the TPU worker.\n",
        "\n",
        "Note: Despite the improved performance, there are tradeoffs with this method compared to running a single step inside a tf.function. Running multiple steps in a tf.function is less flexible—you cannot run things eagerly or arbitrary Python code within the steps."
      ],
      "metadata": {
        "id": "tp-eaDbGX6og"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def train_multiple_steps(iterator, steps):\n",
        "    \"\"\"The step function for one training step.\"\"\"\n",
        "    def step_fn(inputs):\n",
        "        \"\"\"The computation to run on each TPU device.\"\"\"\n",
        "        images, labels = inputs\n",
        "        with tf.GradientTape() as tape:\n",
        "          logits = model(images, training=True)\n",
        "          loss = tf.keras.losses.sparse_categorical_crossentropy(\n",
        "              labels, logits, from_logits=True)\n",
        "          loss = tf.nn.compute_average_loss(loss, global_batch_size=batch_size)\n",
        "\n",
        "        grads = tape.gradient(loss, model.trainable_variables)\n",
        "        optimizer.apply_gradients(list(zip(grads, model.trainable_variables)))\n",
        "\n",
        "        training_loss.update_state(loss * strategy.num_replicas_in_sync)\n",
        "        training_accuracy.update_state(labels, logits)\n",
        "\n",
        "    for _ in tf.range(steps):\n",
        "      strategy.run(step_fn, args=(next(iterator),))"
      ],
      "metadata": {
        "id": "MlVyZE7IXFLt"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert `steps_per_epoch` to `tf.Tensor` so the `tf.function` won't get\n",
        "# retraced if the value changes.\n",
        "train_multiple_steps(train_iterator, tf.convert_to_tensor(steps_per_epoch))\n",
        "\n",
        "print('Current step: {}, training loss: {}, accuracy: {}%'.format(\n",
        "      optimizer.iterations.numpy(),\n",
        "      round(float(training_loss.result()), 4),\n",
        "      round(float(training_accuracy.result()) * 100, 2)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QkHW4clmctxf",
        "outputId": "e008d088-f750-4e83-8ab7-5e76fa5d2abe"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current step: 3329, training loss: 0.0052, accuracy: 99.84%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reference\n",
        "\n",
        "https://www.tensorflow.org/guide/tpu"
      ],
      "metadata": {
        "id": "97i-59f5dA76"
      }
    }
  ]
}