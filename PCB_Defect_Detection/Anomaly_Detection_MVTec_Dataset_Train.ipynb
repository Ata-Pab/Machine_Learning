{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNJoB0hYZusL"
      },
      "source": [
        "## Anomaly Detection in MVTec Dataset\n",
        "\n",
        "Different experiments will be done in this workspace.\n",
        "\n",
        "Used Models:\n",
        "* `ConvAE Model`\n",
        "* `CBAM ConvAE Model`\n",
        "* `Residual CBAM ConvAE Model`\n",
        "\n",
        "Batch size: `16`\n",
        "\n",
        "Epochs: Changes between `500~1000` epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bPX0C3uoHd8z"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import layers, losses\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zI4FQz7cHisY",
        "outputId": "ba9f5b24-7027-4db6-a6a6-7d8843ba844b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qz0KUBTxHiqQ",
        "outputId": "8941ec08-dccb-4479-ea8e-599330cac0de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current working directory /content\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "os.makedirs('utils/', exist_ok=True)\n",
        "os.chdir('utils')\n",
        "\n",
        "! wget -q https://raw.githubusercontent.com/Ata-Pab/Machine_Learning/master/utils/models.py\n",
        "! wget -q https://raw.githubusercontent.com/Ata-Pab/Machine_Learning/master/utils/losses.py\n",
        "! wget -q https://raw.githubusercontent.com/Ata-Pab/Machine_Learning/master/utils/vision.py\n",
        "! wget -q https://raw.githubusercontent.com/Ata-Pab/Machine_Learning/master/utils/callbacks.py\n",
        "! wget -q https://raw.githubusercontent.com/Ata-Pab/Machine_Learning/master/utils/utils.py\n",
        "! wget -q https://raw.githubusercontent.com/Ata-Pab/Machine_Learning/master/utils/attention_modules.py\n",
        "! wget -q https://raw.githubusercontent.com/Ata-Pab/Machine_Learning/master/utils/backbones.py\n",
        "\n",
        "os.chdir('/content')\n",
        "print(\"Current working directory\", os.getcwd())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "HC_JWBMhHin1"
      },
      "outputs": [],
      "source": [
        "from utils import vision\n",
        "from utils import utils\n",
        "from utils import losses\n",
        "from utils import models\n",
        "from utils import backbones\n",
        "from utils import attention_modules\n",
        "from utils.attention_modules import Conv2DLayerBN, Conv2DLayerRes, ChannelGate, SpatialGate, CBAM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LByF8uVLCRMS"
      },
      "source": [
        "### Experiment Setup Start"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "NVBiwmDoCa-V"
      },
      "outputs": [],
      "source": [
        "# Create experiment folder\n",
        "EXPERIMENT_NAME = 'CBAM_ConvAE_Model_MVTec'\n",
        "EXPERIMENT_SAVE_DIR = os.path.join('/content/drive/MyDrive/MASTER/Master_Thesis/Experiments', EXPERIMENT_NAME)\n",
        "EXPERIMENT_PRELOAD_WEIGHTS_FROM = 'experiment_11'  # ex. 'experiment_2'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "AwZDEyRPHnwC"
      },
      "outputs": [],
      "source": [
        "experiment = {\n",
        "    'TYPE': 'train',        # Experiment type: 'train', 'test'\n",
        "    'ACCELERATOR': 'GPU',   # 'CPU', 'GPU' or 'TPU'\n",
        "\n",
        "    # Input data\n",
        "    'DATASET': 'MVTec_metal_nut_Dataset',\n",
        "    'IMAGE_SIZE': (256, 256),\n",
        "    'INPUT_SHAPE': (256, 256, 3),\n",
        "    'PATCH_SIZE': 256,\n",
        "    'MAX_GRID_NUM': 4,      # Number of maximum grids to be used in partitioning the input image\n",
        "    'USE_ENTIRE_IMAGES'     : False,  # Use entire/unpartitioned images as input\n",
        "    'USE_PARTITIONED_IMAGES': True,  # Use partitioned (parameters: PATCH_SIZE, MAX_GRID_NUM) images as input\n",
        "    'VALID_SIZE': 0.1,      # Validation data size: (Valid Data) / (All Data)\n",
        "    'DATA_AUG': False,      # Apply data augmentation\n",
        "    'DATA_AUG_POWER': 2,    # Data augmentation power: How many times data\n",
        "     # augmentation will be applied to the whole dataset. default 1\n",
        "\n",
        "    # Model\n",
        "    'BACKBONE': 'ResCBAM_ConvAE',   # 'ConvAE', 'CBAM_ConvAE' or 'ResCBAM_ConvAE'\n",
        "    'DECODER_ATTENTION': True,      # Valid if backbone has CBAM. If True, CBAM attention layer in both encoder and decoder layer\n",
        "    'REDUCTION_RATIO': 16,          # CBAM layer reduction ratio\n",
        "    'SPARSITY_FACTOR': None,        # The activity regularizer for sparsity in autoencoders - tf.keras.regularizers.l1(0.001)\n",
        "    'FIRST_TRANIABLE_LAYER_IX': None,  # First trainable layer of pre-trained backbone models - \"block4_pool\"\n",
        "    'BATCH_SIZE': 16,               # IF TPU is active set 4, otherwise set anything\n",
        "    'EPOCHS': 5,\n",
        "    'OPTIMIZER': tf.keras.optimizers.Adam,\n",
        "    'LEARNING_RATE': 1e-4,\n",
        "    'LATENT_DIM': 128,  # set latent dim - shape: (LATENT_DIM, 1) - default 200\n",
        "\n",
        "    # Loss\n",
        "    'RECONS_LOSS': losses.ssim_loss, # Reconstruction loss (use tf intrinsic methods: tf.keras.losses.mean_squared_error or losses.ssim_loss)\n",
        "    'LRELU_SLOPE': 0.2,       # Leaky ReLU activation function slope value\n",
        "    # Perceptual Loss\n",
        "    'PERCEPTUAL_LOSS': False, # Use Perceptual loss\n",
        "    'PERCEPTUAL_LOSS_MODEL': 'ResNet50', # 'custom', 'VGG16', 'VGG19', 'ResNet50' - default 'VGG16'\n",
        "    'PERCEPTUAL_LAYERS': [35,77,139,150],    # 'conv2_block3_3_conv', 'conv3_block4_3_conv', 'conv4_block6_3_conv', 'conv5_block1_3_conv'\n",
        "    'PERP_LOSS_LAMBDA': 1,      # Perceptual loss coeff\n",
        "    'MSE_LOSS_LAMBDA': 0.5,     # MSE coeff\n",
        "\n",
        "    # Evaluation\n",
        "    'BIN_MASK_THRSD': 0.5,  # Binary mask threshold\n",
        "    'MAX_TEST_IMAGES': -1,  # default: -1, Get all images from the testing dataset\n",
        "\n",
        "    # Save model\n",
        "    'PRE_LOAD_WEIGHTS': None, # Start to train model with initial weights come from previous training process - Set epoch number (50, 100, etc.)\n",
        "    'SAVE_WEIGHTS_PER_EPOCH': 5,  # Checkpoints\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "np8ZSB0UDAdu"
      },
      "outputs": [],
      "source": [
        "if experiment['TYPE'] == 'train':\n",
        "    assert(EXPERIMENT_NAME != '...')\n",
        "    # Create experiment folder\n",
        "    os.makedirs(EXPERIMENT_SAVE_DIR, exist_ok=True)\n",
        "\n",
        "    # Model checkpoints will be save in exp_save_dir\n",
        "    exp_save_dir = utils.create_experimental_output(experiment, EXPERIMENT_SAVE_DIR)\n",
        "\n",
        "    TRAINING_WEIGHT_DIR = os.path.join(exp_save_dir, 'training_weights')\n",
        "    # Create folder for checkpoints (training weights)\n",
        "    os.makedirs(TRAINING_WEIGHT_DIR, exist_ok=True)\n",
        "\n",
        "    if experiment['PRE_LOAD_WEIGHTS'] != None:\n",
        "        assert(EXPERIMENT_PRELOAD_WEIGHTS_FROM != None)\n",
        "        # Start to train model with initial weights come from previous training process\n",
        "        exp_save_dir = os.path.join(EXPERIMENT_SAVE_DIR, EXPERIMENT_PRELOAD_WEIGHTS_FROM)\n",
        "        PRE_LOAD_WEIGHT_DIR = os.path.join(exp_save_dir, 'training_weights')\n",
        "else:  # test mode\n",
        "    assert(EXPERIMENT_PRELOAD_WEIGHTS_FROM != None)\n",
        "    # Set experiment save directory and training weight directory manually\n",
        "    exp_save_dir = exp_save_dir = os.path.join(EXPERIMENT_SAVE_DIR, EXPERIMENT_PRELOAD_WEIGHTS_FROM)\n",
        "    TRAINING_WEIGHT_DIR = os.path.join(exp_save_dir, 'training_weights')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dTRbCm07Gdky"
      },
      "outputs": [],
      "source": [
        "print(f\"...Experiment {exp_save_dir.split('experiment_')[1]} was initialized...\")\n",
        "print(f\"Experiment directory: {EXPERIMENT_SAVE_DIR}\")\n",
        "print(f\"Training weights save directory: {TRAINING_WEIGHT_DIR}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDMM7HtwGgVK"
      },
      "source": [
        "### Experiment Setup End"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bev4jkOvNJkj"
      },
      "source": [
        "### Dataset Pre-processing Start"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NQ7Ry25NldNJ"
      },
      "outputs": [],
      "source": [
        "# MVTec Transistor dataset from Kaggle\n",
        "# https://www.kaggle.com/datasets/leezhixiong/mvtec-transistor-dataset\n",
        "\n",
        "! pip install -q kaggle\n",
        "\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "! kaggle datasets download -d ipythonx/mvtec-ad\n",
        "\n",
        "utils.unzip_data(\"/content/mvtec-ad.zip\")\n",
        "! rm /content/mvtec-ad.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-sXZh-rD8lj"
      },
      "source": [
        "Set MVTec Dataset Paths for sub datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "GJFvl3gBBxRa"
      },
      "outputs": [],
      "source": [
        "ROOT_PATH = \"/content\"\n",
        "\n",
        "# Parse experiment dataset config, get sub dataset folder name\n",
        "subfolder_name = ((experiment['DATASET'].split(\"MVTec_\")[-1]).split(\"_Dataset\")[0])\n",
        "TRAIN_DATASET_GOOD_PATH = os.path.join(ROOT_PATH, (subfolder_name + \"/train/good\"))\n",
        "TRAIN_DATASET_DEFECT_PATH = None\n",
        "\n",
        "TEST_DATASET_GOOD_PATH = os.path.join(ROOT_PATH, (subfolder_name + \"/test/good\"))\n",
        "TEST_DATASET_DEFECT_PATH = os.path.join(ROOT_PATH, (subfolder_name + \"/test\"))\n",
        "GND_DATASET_DEFECT_PATH = os.path.join(ROOT_PATH, (subfolder_name + \"/ground_truth\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NXbQ-fLoEcQY"
      },
      "outputs": [],
      "source": [
        "print(\"TRAIN DATASET GOOD\")\n",
        "# Do not need to separate training dataset into train_good and train_defect (unsupervised learning)\n",
        "# Do not need to sort train dataset files, they already will be shuffled\n",
        "train_dataset_files = utils.get_all_img_files_in_directory(TRAIN_DATASET_GOOD_PATH, ext=\"png\", verbose=1)\n",
        "\n",
        "#print(\"TEST DATASET GOOD\")\n",
        "#test_dataset_good_files = utils.get_all_img_files_in_directory(TEST_DATASET_GOOD_PATH, ext=\"png\", verbose=1)\n",
        "\n",
        "print(\"TEST DATASET DEFECTED\")\n",
        "# Exclude Test Dataset Good Files, get all others\n",
        "test_dataset_defect_files = utils.get_all_img_files_in_directory(TEST_DATASET_DEFECT_PATH, ext=\"png\", exc=\"good\", verbose=1)\n",
        "# Sort ground truth dataset according to image file names\n",
        "test_dataset_defect_files = sorted(test_dataset_defect_files)\n",
        "\n",
        "print(\"GROUND TRUTH DATASET DEFECTED\")\n",
        "gnd_dataset_defect_files = utils.get_all_img_files_in_directory(GND_DATASET_DEFECT_PATH, ext=\"png\", verbose=1)\n",
        "# Sort ground truth dataset according to image file names\n",
        "gnd_dataset_defect_files = sorted(gnd_dataset_defect_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "BVXWZlnAHnto"
      },
      "outputs": [],
      "source": [
        "LABELS = [\"Defect-free\", \"Defected\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFRBWix0Rn6q"
      },
      "source": [
        "Training dataset Validation Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dkdGUkEtQlb2"
      },
      "outputs": [],
      "source": [
        "# Training/Validation Split\n",
        "train_valid_separator = len(train_dataset_files) - int(len(train_dataset_files) * experiment['VALID_SIZE'])\n",
        "\n",
        "print(f\"Number of defect free {subfolder_name} images in the training dataset: {len(train_dataset_files[:train_valid_separator])}\")\n",
        "print(f\"Number of defect free {subfolder_name} images in the validation dataset: {len(train_dataset_files[train_valid_separator:])}\")\n",
        "print(f\"Number of defect free {subfolder_name} images: {len(train_dataset_files[:train_valid_separator])+len(train_dataset_files[train_valid_separator:])}\")\n",
        "print(f\"Number of defected {subfolder_name} images in the testing dataset: {len(test_dataset_defect_files)}\")\n",
        "#print(f\"Number of defect free {subfolder_name} images in the testing dataset: {len(test_dataset_good)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3FJ33gy-VIRE"
      },
      "outputs": [],
      "source": [
        "test_img = utils.load_images(train_dataset_files[1], scl=True)\n",
        "'''  Uncomment in evaluation notebook\n",
        "print(f\"Test image shape: {test_img.shape}\")\n",
        "\n",
        "plt.imshow(test_img)\n",
        "plt.axis('off')\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ib1zmWbDnbwq"
      },
      "source": [
        "Get Modified Image size and number of Width/Height grids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Phz6GfrPTLlr"
      },
      "outputs": [],
      "source": [
        "modified_image_size, grid_width, grid_height = utils.get_new_image_size_according_to_patch_size(test_img.shape[:2],\n",
        "                                                                                                experiment['PATCH_SIZE'],\n",
        "                                                                                                max_grid_num=experiment['MAX_GRID_NUM'],\n",
        "                                                                                                verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ShNPDy4OEE1j"
      },
      "source": [
        "Data Augmentation Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "PqLc2ncLEECS"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "if experiment['DATA_AUG']:\n",
        "    # Setup data augmentation\n",
        "    data_aug_layer = Sequential([\n",
        "      #preprocessing.RandomFlip(\"horizontal_and_vertical\"), # randomly flip images on horizontal/vertical edge\n",
        "      #preprocessing.RandomRotation(0.2), # randomly rotate images by a specific amount\n",
        "      #preprocessing.RandomZoom(0.2), # randomly zoom into an image\n",
        "      tf.keras.layers.RandomBrightness(factor=0.2, value_range=[0.0, 1.0], seed=None),\n",
        "      # value_range parameter should be [0.0, 1.0] for RandomBrightness\n",
        "      # if images were scaled before, default value is [0,255]\n",
        "      tf.keras.layers.RandomContrast(0.2, seed=None),\n",
        "      #tf.keras.layers.RandomCrop(256, 256, seed=None), Error - Image size changes\n",
        "      #preprocessing.RandomWidth(0.2), # randomly adjust the width of an image by a specific amount\n",
        "      #preprocessing.RandomHeight(0.2), # randomly adjust the height of an image by a specific amount\n",
        "      #preprocessing.Rescaling(1./255) # keep for models like ResNet50V2, remove for EfficientNet\n",
        "    ], name=\"data_aug_layer\")\n",
        "else:\n",
        "    data_aug_layer = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Kln9nRgJuKA3"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "random.seed(24)\n",
        "\n",
        "random.shuffle(train_dataset_files)\n",
        "train_dataset_files = train_dataset_files[:train_valid_separator]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i6dhzQbTaJvd"
      },
      "outputs": [],
      "source": [
        "print(f\"Number of {subfolder_name} images in the training dataset: {len(train_dataset_files)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fc0XepHPULpf"
      },
      "source": [
        "Create TF Dataset Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L178FabCIAGp"
      },
      "outputs": [],
      "source": [
        "# Use partititoned images as input (Parameters: PATCH_SIZE and MAX_GRID_NUM)\n",
        "if experiment['USE_PARTITIONED_IMAGES']:\n",
        "    train_dataset = utils.create_dataset_pipeline(train_dataset_files, batch_size=experiment['BATCH_SIZE'], shuffle=True,\n",
        "                                                  img_size=modified_image_size, scl=True, patch_size=experiment['PATCH_SIZE'],\n",
        "                                                  entire_img_pathes=experiment['USE_ENTIRE_IMAGES'], aug_layer=data_aug_layer,\n",
        "                                                  data_aug_power=experiment['DATA_AUG_POWER'], accelerator='GPU')\n",
        "# Use only entire images dataset as input\n",
        "else:\n",
        "    train_dataset = utils.create_dataset_pipeline(train_dataset_files, batch_size=experiment['BATCH_SIZE'], shuffle=True,\n",
        "                                                      img_size=experiment['IMAGE_SIZE'], scl=True, patch_size=None,\n",
        "                                                      aug_layer=data_aug_layer, data_aug_power=experiment['DATA_AUG_POWER'],\n",
        "                                                      accelerator='GPU')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gq956asgJfTU"
      },
      "outputs": [],
      "source": [
        "train_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ibteMHUIAEF",
        "outputId": "7ce58108-3f23-47db-9db6-8b73959978fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of batches to be trained:  50\n"
          ]
        }
      ],
      "source": [
        "print(\"Number of batches to be trained: \", len(train_dataset))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9nFqSWqNYEa"
      },
      "source": [
        "### Dataset Pre-processing End"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "VfBwh_D1lgsd",
        "outputId": "c0d9d1ff-1a23-446b-ee80-5bd3030b3687"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'  Uncomment in evaluation notebook\\nvision.show_image_samples_from_batch(train_dataset)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "'''  Uncomment in evaluation notebook\n",
        "vision.show_image_samples_from_batch(train_dataset)\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5bv9YDCyUZL"
      },
      "source": [
        "### Model Training Start"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uH2v1uOqyXeW"
      },
      "source": [
        "Create Custom Anomaly Detection Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "laHeiaK6tvj7",
        "outputId": "d1b6c645-b98e-4b76-decd-572662711b36"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'  Uncomment in evaluation notebook\\ncustom_model.summary()\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "if experiment['BACKBONE'] == 'ConvAE':\n",
        "    # ConvAE Model\n",
        "    custom_model = backbones.build_ConvAEModelV1(input_shape=experiment['INPUT_SHAPE'],\n",
        "                                             latent_dim=experiment['LATENT_DIM'],\n",
        "                                             lrelu_alpha=experiment['LRELU_SLOPE'],\n",
        "                                             sparsity=experiment['SPARSITY_FACTOR'])\n",
        "elif experiment['BACKBONE'] == 'CBAM_ConvAE':\n",
        "    # CBAM ConvAE Model\n",
        "    custom_model = backbones.build_CBAMConvAEModelV1(input_shape=experiment['INPUT_SHAPE'],\n",
        "                                                 latent_dim=experiment['LATENT_DIM'],\n",
        "                                                 reduction_ratio=experiment['REDUCTION_RATIO'],\n",
        "                                                 attention_for_decoder=experiment['DECODER_ATTENTION'],\n",
        "                                                 lrelu_alpha=experiment['LRELU_SLOPE'],\n",
        "                                                 sparsity=experiment['SPARSITY_FACTOR'])\n",
        "elif experiment['BACKBONE'] == 'ResCBAM_ConvAE':\n",
        "    # Residual CBAM ConvAE Model\n",
        "    custom_model = backbones.build_ResCBAMConvAEModelV1(input_shape=experiment['INPUT_SHAPE'],\n",
        "                                                    latent_dim=experiment['LATENT_DIM'],\n",
        "                                                    reduction_ratio=experiment['REDUCTION_RATIO'],\n",
        "                                                    attention_for_decoder=experiment['DECODER_ATTENTION'],\n",
        "                                                    lrelu_alpha=experiment['LRELU_SLOPE'],\n",
        "                                                    sparsity=experiment['SPARSITY_FACTOR'])\n",
        "'''  Uncomment in evaluation notebook\n",
        "custom_model.summary()\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "uTOchdYYNrJC"
      },
      "outputs": [],
      "source": [
        "def generate_and_save_images(model, epoch, test_input):\n",
        "  # All layers run in inference mode (batchnorm).\n",
        "  predictions = model(test_input, training=False)\n",
        "\n",
        "  print(\"test_input.shape: \", test_input.shape)\n",
        "  print(\"predictions.shape: \", predictions.shape)\n",
        "\n",
        "  fig = plt.figure(figsize=(4,4))\n",
        "\n",
        "  for i in range(predictions.shape[0]):\n",
        "    plt.subplot(4, 4, i+1)\n",
        "    plt.imshow(np.array((predictions[i, :, :, :] * 255)).astype(np.uint8))\n",
        "    plt.axis('off')\n",
        "    if i >= 15:\n",
        "      break\n",
        "\n",
        "  #plt.savefig(experiment['IMGS_DIR'] + '/image_at_epoch_{:d}.png'.format(epoch))\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "1B-y5jGrOBY_"
      },
      "outputs": [],
      "source": [
        "if experiment['ACCELERATOR'] != 'TPU':\n",
        "  @tf.function\n",
        "  def train_step(images):\n",
        "      with tf.GradientTape() as tape:\n",
        "          generated_images = custom_model(images, training=True)\n",
        "          #loss = custom_model.compute_mse_perceptual(images, generated_images)\n",
        "          loss = custom_model.loss(images, generated_images)\n",
        "\n",
        "      gradients = tape.gradient(loss, custom_model.trainable_variables)\n",
        "      custom_model.optimizer.apply_gradients(zip(gradients, custom_model.trainable_variables))\n",
        "\n",
        "      return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "_Li6pMMpPr27"
      },
      "outputs": [],
      "source": [
        "from IPython import display\n",
        "import time\n",
        "\n",
        "if experiment['ACCELERATOR'] != 'TPU':\n",
        "  def train(dataset, epochs):\n",
        "      loss_hist = []  # Keep loss history\n",
        "      for epoch in range(epochs):\n",
        "          start = time.time()\n",
        "          for image_batch in dataset:\n",
        "              loss = train_step(image_batch)\n",
        "\n",
        "          loss_hist.append(loss)   # Add loss value to the loss history after each epoch\n",
        "          print(\"loss: \", tf.reduce_mean(loss).numpy())\n",
        "\n",
        "          # Set real epoch value for progressive training process\n",
        "          real_epoch = epoch\n",
        "          if experiment['PRE_LOAD_WEIGHTS'] != None:\n",
        "              real_epoch += experiment['PRE_LOAD_WEIGHTS']\n",
        "\n",
        "          # Save the model every experiment['SAVE_WEIGHTS_PER_EPOCH'] epochs\n",
        "          if (real_epoch + 1) % experiment['SAVE_WEIGHTS_PER_EPOCH'] == 0:\n",
        "            seed = image_batch[:experiment['BATCH_SIZE']]\n",
        "            display.clear_output(wait=True)\n",
        "            generate_and_save_images(custom_model,\n",
        "                                      real_epoch + 1,\n",
        "                                      seed)\n",
        "\n",
        "            # Save checkpoints\n",
        "            utils.save_experiment_checkpoints([custom_model], epoch=(real_epoch+1), save_dir=TRAINING_WEIGHT_DIR)\n",
        "\n",
        "            print ('Time for epoch {} is {} sec'.format(real_epoch + 1, time.time()-start))\n",
        "\n",
        "      # Generate after the final epoch\n",
        "      display.clear_output(wait=True)\n",
        "      generate_and_save_images(custom_model,\n",
        "                              real_epoch+1,\n",
        "                              seed)\n",
        "\n",
        "      return loss_hist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tLaLYuRpQ2G-"
      },
      "outputs": [],
      "source": [
        "if experiment['TYPE'] == 'train':\n",
        "    custom_model.compile(loss=experiment['RECONS_LOSS'],\n",
        "                         optimizer=experiment['OPTIMIZER'](learning_rate=experiment['LEARNING_RATE']))\n",
        "\n",
        "    # Start training the model with previously trained weights\n",
        "    if experiment['PRE_LOAD_WEIGHTS'] != None:\n",
        "        # Start to train model with initial weights come from previous training process\n",
        "        utils.load_model_experiment_weights([custom_model], epoch=experiment['PRE_LOAD_WEIGHTS'], load_dir=PRE_LOAD_WEIGHT_DIR)\n",
        "\n",
        "    custom_model_hist = train(train_dataset, experiment['EPOCHS'])\n",
        "else:  # test/inference mode\n",
        "    # Set load weight epoch number manually\n",
        "    utils.load_model_experiment_weights([custom_model], epoch=experiment['EPOCHS'], load_dir=TRAINING_WEIGHT_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zWhbwHXaz8Do"
      },
      "outputs": [],
      "source": [
        "'''  Uncomment in evaluation notebook\n",
        "if experiment['TYPE'] == 'train':\n",
        "    utils.remove_training_weights_except_last_epoch(TRAINING_WEIGHT_DIR)  # Remove weights except last epoch's\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hrN6ppipQvCc"
      },
      "outputs": [],
      "source": [
        "if experiment['TYPE'] == 'train':\n",
        "    plt.plot(custom_model_hist)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hc3YuITO3WRV"
      },
      "source": [
        "### Model Training End"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Terminate session programmatically"
      ],
      "metadata": {
        "id": "2fuoxfDZ7cWS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ],
      "metadata": {
        "id": "9ea4um_K6_tm"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}