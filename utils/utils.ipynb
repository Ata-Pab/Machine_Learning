{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Data Augmentation\n",
        "\n",
        "**Adding Data Augmentation into the model**\n",
        "\n",
        "This a relatively new feature added to TensorFlow 2.2+ but it's very powerful. Adding a data augmentation layer to the model has the following benefits:\n",
        "\n",
        "* Preprocessing of the images (augmenting them) happens on the **GPU** rather than on the CPU (much faster).\n",
        "* Images are best preprocessed on the GPU where as text and structured data are more suited to be preprocessed on the CPU.\n",
        "* Image data augmentation only happens during training so we can still export our whole model and use it elsewhere. And if someone else wanted to train the same model as us, including the same kind of data augmentation, they could.\n",
        "\n",
        "Data augmentation methods that can be adjusted with Keras:\n",
        "\n",
        "* **RandomFlip** - flips image on horizontal or vertical axis.\n",
        "* **RandomRotation** - randomly rotates image by a specified amount.\n",
        "* **RandomZoom** - randomly zooms into an image by specified amount.\n",
        "* **RandomHeight** - randomly shifts image height by a specified amount.\n",
        "* **RandomWidth** - randomly shifts image width by a specified amount.\n",
        "* **Rescaling** - normalizes the image pixel values to be between 0 and 1,"
      ],
      "metadata": {
        "id": "CzIiQcg43RPG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "\n",
        "data_augmentation = keras.Sequential([\n",
        "    preprocessing.RandomFlip(\"horizontal\"),  # \"horizontal\", \"vertical\", or \"horizontal_and_vertical\"\n",
        "    preprocessing.RandomRotation(0.2),\n",
        "    preprocessing.RandomZoom(0.2),\n",
        "    preprocessing.RandomHeight(0.2),\n",
        "    preprocessing.RandomWidth(0.2),\n",
        "    preprocessing.Rescaling(1./255) # keep for ResNet50V2, remove for EfficientNetB0\n",
        "], name='data_aug_layer')\n",
        "\n",
        "# # Example Usage\n",
        "# data augmentation model requires shape (None, height, width, 3)\n",
        "# augmented_img = data_augmentation(tf.expand_dims(img, axis=0))\n",
        "# plt.imshow(tf.squeeze(augmented_img)/255.) # requires normalization after augmentation"
      ],
      "metadata": {
        "id": "N5MFUm3C17a8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using Dropout Technique to overcome the Overfitting problem\n",
        "\n",
        "A form of regularization useful in training neural networks. Dropout regularization removes a random selection of a fixed number of the units in a network layer for a single gradient step. The more units dropped out, the stronger the regularization."
      ],
      "metadata": {
        "id": "-maMWrmvmshF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "model = keras.Sequential([\n",
        "  keras.layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
        "  keras.layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "  keras.layers.MaxPooling2D(),\n",
        "  keras.layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "  keras.layers.MaxPooling2D(),\n",
        "  keras.layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "  keras.layers.MaxPooling2D(),\n",
        "  keras.layers.Dropout(0.2),   # Adding Dropout layer before flatten the data\n",
        "  keras.layers.Flatten(),\n",
        "  keras.layers.Dense(128, activation='relu'),\n",
        "  keras.layers.Dense(num_classes, name=\"outputs\")\n",
        "])"
      ],
      "metadata": {
        "id": "_gBxarZYmOJR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Layers Describe - Print Model Layer's name, number & trainable state"
      ],
      "metadata": {
        "id": "c_8WyOIJEnmA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def describe_model_layers(model):\n",
        "  for layer_number, layer in enumerate(model.layers):\n",
        "    print(layer_number, layer.name, layer.trainable)"
      ],
      "metadata": {
        "id": "eIEUkruX17Yo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Unzip File"
      ],
      "metadata": {
        "id": "u-kr9qOhQv3k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "# Unzip the downloaded file\n",
        "def unzip_data(zip_file_name):\n",
        "  zip_ref = zipfile.ZipFile(zip_file_name, \"r\")\n",
        "  zip_ref.extractall()\n",
        "  zip_ref.close()"
      ],
      "metadata": {
        "id": "3YApMsJoQvMG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Print working or data directory map - walk through directory"
      ],
      "metadata": {
        "id": "CwNdF1uJQ1ou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def walk_through_dir(data_dir):\n",
        "  for dirpath, dirnames, filenames in os.walk(data_dir):\n",
        "    print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")"
      ],
      "metadata": {
        "id": "378BgF0tQvJp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get Images from Directory as Numpy Array"
      ],
      "metadata": {
        "id": "YwCYLv6ATsS8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "import glob   # In order to get images as matrices from directory\n",
        "\n",
        "def get_imgs_from_directory_as_numpy_array(dir, ext, size=None, scl=None):\n",
        "    formats = ['jpg', 'png', 'jpeg']\n",
        "\n",
        "    if ext in formats:\n",
        "        rgx_for_img = dir + \"/*.\" + ext\n",
        "        img_list = glob.glob(rgx_for_img)\n",
        "    def process_images(filename):\n",
        "        img = keras.preprocessing.image.load_img(filename, color_mode=\"rgb\", target_size=size)\n",
        "        img_arr = keras.preprocessing.image.img_to_array(img)\n",
        "        img_arr = np.array(img_arr).astype('float32')\n",
        "        if scl == '8bit': img_arr /= 255.0\n",
        "        return img_arr\n",
        "\n",
        "    return np.array(list(map(process_images, img_list)))\n",
        "    # https://keras.io/api/preprocessing/image/\n",
        "    # https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator"
      ],
      "metadata": {
        "id": "EKzIwB_fTrgZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prepare Images as Keras Input"
      ],
      "metadata": {
        "id": "NqQYrD9Xd13q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_imgs_as_keras_input(np_array, input_size):\n",
        "  '''This method prepares a data array as a keras input\n",
        "  Example of input_size parameter usage: (28,28,1) -> 28x28 pixels gray scale images, (28,28,3) 28x28 pixels RGB images\n",
        "  Example of np_array parameter usage: np_array.shape = (60000, 28, 28) OR (60000, 784)'''\n",
        "  w, h, d = input_size\n",
        "  return np_array.reshape(np_array.shape[0], w, h, d)"
      ],
      "metadata": {
        "id": "9Q9liij9dyqU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocess Image File - Load image as tf format, Reshape & Scale"
      ],
      "metadata": {
        "id": "rD4-tCYWUTDo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_img(filename, img_shape=224, num_channels=3, scale=True):\n",
        "  \"\"\"\n",
        "  Create a function to import an image and resize it to be able to be used with custom models\n",
        "  Reads an image from filename, turns it into a tensor\n",
        "  and reshapes it to (img_shape, img_shape, colour_channel).\n",
        "    Default image size of ResNet model\n",
        "    Default number of channels=3 (RGB)\n",
        "  \"\"\"\n",
        "  # Read in target file (an image)\n",
        "  img = tf.io.read_file(filename)\n",
        "\n",
        "  # Decode the read file into a tensor\n",
        "  img = tf.image.decode_image(img, channels=num_channels)\n",
        "\n",
        "  # Resize the image (to the same size our model was trained on)\n",
        "  img = tf.image.resize(img, size = [img_shape, img_shape])\n",
        "\n",
        "  # Rescale the image (get all values between 0 and 1)\n",
        "  if scale:\n",
        "    img = img/255.\n",
        "\n",
        "  return img"
      ],
      "metadata": {
        "id": "d2NPHG8AQvHO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prediction for given image file & Plots"
      ],
      "metadata": {
        "id": "r6hhk-gWVGjc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pred_and_plot(model, filename, class_names):\n",
        "  \"\"\"\n",
        "  Imports an image located at filename, makes a prediction on it with\n",
        "  a trained model and plots the image with the predicted class as the title.\n",
        "  \"\"\"\n",
        "  # Import the target image and preprocess it\n",
        "  img = load_and_prep_image(filename)\n",
        "\n",
        "  # Make a prediction\n",
        "  pred = model.predict(tf.expand_dims(img, axis=0))\n",
        "\n",
        "  # Get the predicted class\n",
        "  pred_class = class_names[int(tf.round(pred)[0][0])]\n",
        "\n",
        "  # Plot the image and predicted class\n",
        "  plt.imshow(img)\n",
        "  plt.title(f\"Prediction: {pred_class}\")\n",
        "  plt.axis(False);"
      ],
      "metadata": {
        "id": "-6RL7zAJVE9c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prediction Analyzer - Prints DataFrame for Most wrong or Correct Predicted Data\n"
      ],
      "metadata": {
        "id": "VOUFBEapIIEn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def get_prediction_analysis(img_file_paths, y_true, y_pred, pred_probs, y_true_class_names=None, y_pred_class_names=None, analysis='bad'):\n",
        "  assert (analysis == 'bad' or  analysis == 'good'), \"Invalid analysis type. Please choose one of 'good', 'bad', analysis types\"\n",
        "\n",
        "  dataframe = {\"img_path\": img_file_paths,\n",
        "             \"y_true\": y_true,\n",
        "             \"y_pred\": y_pred,\n",
        "             \"pred_conf\": pred_probs.max(axis=1), # get the maximum prediction probability value\n",
        "             \"y_true_classname\": [class_names[i] for i in y_labels],\n",
        "             \"y_pred_classname\": [class_names[i] for i in pred_classes]}\n",
        "\n",
        "  pred_df = pd.DataFrame(dataframe)\n",
        "  pred_df['pred_correct'] = pred_df['y_true'] == pred_df['y_pred']\n",
        "\n",
        "  # Get Wrong predictions\n",
        "  if analysis == 'bad':\n",
        "    wrong_preds = pred_df[pred_df['pred_correct'] == False]\n",
        "    wrong_preds = wrong_preds.sort_values('pred_conf', ascending=False)[:100]  # Most wrong 100 predictions\n",
        "    return wrong_preds\n",
        "  elif analysis == 'good':\n",
        "    good_preds = pred_df[pred_df['pred_correct'] == True]\n",
        "    good_preds = good_preds.sort_values('pred_conf', ascending=False)[:100]  # Most correct 100 predictions\n",
        "    return good_preds\n",
        "\n",
        "\n",
        "# # Example Usage\n",
        "# wrong_preds = get_prediction_analysis(img_file_paths, y_true, y_pred, pred_probs, [class_names[i] for i in y_true], [class_names[i] for i in y_pred])\n",
        "# wrong_preds.head()\n",
        "#\n",
        "# # Visualize some of the most wrong predictions\n",
        "#\n",
        "# images_to_view = 16\n",
        "# start_ix = 11\n",
        "# plt.figure(figsize=(15,10))\n",
        "#\n",
        "# for i, row in enumerate(wrong_preds[start_ix:start_ix+images_to_view].itertuples()):\n",
        "#   plt.subplot(4, 4, i+1)\n",
        "#   img = load_and_prep_image(row[1], scale=True)\n",
        "#   _, _, _, _, pred_prob, y_true, y_pred, _ = row # only interested in a few parameters of each row\n",
        "#   plt.imshow(img)\n",
        "#   plt.title(f\"actual: {y_true}, pred: {y_pred} \\nprob: {pred_prob:.2f}\")\n",
        "#   plt.axis(False)"
      ],
      "metadata": {
        "id": "6AFVNZv-IMDf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Print Grid Search Results"
      ],
      "metadata": {
        "id": "JTdpt9c4g_xE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_grid_search_results(search):\n",
        "  '''This methods prints Grid Search Results for given search algorithm'''\n",
        "  print(\"==== Grid Search Results ====\")\n",
        "  print(\"best_estimator: \", search.best_estimator_)\n",
        "  print(\"best_params:    \", search.best_params_)\n",
        "  print(\"best_score:      {:.3f}\".format(search.best_score_))"
      ],
      "metadata": {
        "id": "NLrujyFihCfI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TF Keras Callbacks"
      ],
      "metadata": {
        "id": "BhCk5FEE5GKB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "tf.keras.callbacks is a module in TensorFlow that provides various functions that can be used to monitor and modify the behavior of the training process of a neural network. These callbacks can be passed as a list to the fit() method of a tf.keras.Model object, allowing you to customize the training process.\n",
        "\n",
        "Some of the commonly used callbacks are:\n",
        "\n",
        "* **ModelCheckpoint**: This callback saves the model after every epoch, or only when an improvement in performance is observed. This helps you to save the best performing model and avoid overfitting. The ModelCheckpoint callback gives you the ability to save your model, as a whole in the SavedModel format or the weights (patterns) only to a specified directory as it trains. This is helpful if you think your model is going to be training for a long time and you want to make backups of it as it trains. It also means if you think your model could benefit from being trained for longer, you can reload it from a specific checkpoint and continue training from there. For example, say you fit a feature extraction transfer learning model for 5 epochs and you check the training curves and see it was still improving and you want to see if fine-tuning for another 5 epochs could help, you can load the checkpoint, unfreeze some (or all) of the base model layers and then continue training.\n",
        "\n",
        "* **EarlyStopping**: This callback stops the training process when the validation loss stops improving. This helps you to avoid overfitting and saves training time.\n",
        "\n",
        "* **TensorBoard**: This callback writes a log for TensorBoard, which can be used to visualize the model training process, including metrics like loss and accuracy, and graph visualizations of the model architecture.\n",
        "\n",
        "* **ReduceLROnPlateau**: This callback reduces the learning rate when the validation loss stops improving, which can help you to fine-tune the model.\n",
        "\n",
        "* **CSVLogger**: This callback writes the training and validation metrics to a CSV file at the end of each epoch, which can be useful for monitoring and analyzing the performance of the model.\n",
        "\n",
        "These are just a few examples of the many callbacks available in tf.keras.callbacks. You can also create your own custom callbacks by subclassing tf.keras.callbacks.Callback."
      ],
      "metadata": {
        "id": "4pSg1hWI5Kw1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Model Checkpoint callback"
      ],
      "metadata": {
        "id": "2Jw87a-K62xM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "import tensorflow as tf\n",
        "\n",
        "def create_model_checkpoint_callback(path, experiment_name, verbose=1):\n",
        "  # Get Datetime object containing current date and time\n",
        "  date = str(datetime.now())\n",
        "  date = (((date.replace(\"-\", \"_\")).replace(\":\", \"_\")).replace(\" \", \"_\")).split(\".\")[0]\n",
        "\n",
        "  checkpoint_path = path + \"/\" + experiment_name + \"/\" + date + \"/checkpoint.ckpt\"\n",
        "\n",
        "  # Create a ModelCheckpoint callback that saves the model's weights only\n",
        "  checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                         save_weights_only=True, # set to False to save the entire model\n",
        "                                                         # If disk space is an issue, saving the weights only is faster and takes up less space than saving the whole model.\n",
        "                                                         save_best_only=False,   # set to True to save only the best model instead of a model every epoch\n",
        "                                                         monitor='val_loss',     # Use \"loss\" or \"val_loss\" to monitor the model's total loss.\n",
        "                                                         save_freq='epoch',      # save every epoch\n",
        "                                                         verbose=1)\n",
        "  if verbose > 0:\n",
        "    print(f\"Model checkpoint will save to: {checkpoint_path}\")\n",
        "\n",
        "  return checkpoint_callback\n",
        "\n",
        "# # Example usage\n",
        "# model_history = model.fit(x_train, y_train, epochs=5, ...,\n",
        "#                          callbacks=[create_model_checkpoint_callback(dir_name='tensorflow_hub', experimodelB0')])\n",
        "\n",
        "# # Assigning Multiple callbacks\n",
        "# model_history = model.fit(x_train, y_train, epochs=5, ...,\n",
        "#                          callbacks=[create_model_checkpoint_callback(dir_name='tensorflow_hub', experimodelB0'),\n",
        "#                          create_tensorboard_callback(dir_name='tensorflow_hub', experimodelB0')])\n",
        "#\n",
        "# # OR\n",
        "#\n",
        "# callback_list = [create_early_stopping_callback(), create_model_checkpoint_callback(dir_name='tensorflow_hub', experimodelB0'), create_tensorboard_callback(dir_name='tensorflow_hub', experimodelB0')]\n",
        "# model_history = model.fit(x_train, y_train, epochs=5, ..., callbacks=callback_list)"
      ],
      "metadata": {
        "id": "loqr-Ovv6Tdp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create TensorBoard callback"
      ],
      "metadata": {
        "id": "R9kvMgzbTZro"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "import tensorflow as tf\n",
        "\n",
        "def create_tensorboard_callback(path, experiment_name, verbose=1):\n",
        "  '''\n",
        "  TensorBoard is a visualization tool provided with TensorFlow.\n",
        "  This callback logs events for TensorBoard, including:\n",
        "\n",
        "  * Metrics summary plots\n",
        "  * Training graph visualization\n",
        "  * Weight histograms\n",
        "  * Sampled profiling\n",
        "  '''\n",
        "  # Get Datetime object containing current date and time\n",
        "  date = str(datetime.now())\n",
        "  date = (((date.replace(\"-\", \"_\")).replace(\":\", \"_\")).replace(\" \", \"_\")).split(\".\")[0]\n",
        "  log_dir = path + \"/\" + experiment_name + \"/\" + date\n",
        "\n",
        "  tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
        "      log_dir=log_dir,\n",
        "      write_graph=True,\n",
        "      histogram_freq=0,\n",
        "      '''\n",
        "      update_freq: 'batch' or 'epoch' or integer. When using 'epoch', writes\n",
        "      the losses and metrics to TensorBoard after every epoch. If using an\n",
        "      integer, let's say 1000, all metrics and losses (including custom ones\n",
        "      added by Model.compile) will be logged to TensorBoard every 1000 batches.\n",
        "      'batch' is a synonym for 1, meaning that they will be written every batch.\n",
        "      '''\n",
        "      update_freq='epoch',\n",
        "  )\n",
        "\n",
        "  if verbose > 0:\n",
        "    print(f\"TensorBoard log files will save to: {log_dir}\")\n",
        "  return tensorboard_callback\n",
        "\n",
        "# # Example usage\n",
        "# model_history = model.fit(x_train, y_train, epochs=5, ...,\n",
        "#                          callbacks=[create_tensorboard_callback(dir_name='tensorflow_hub', experimodelB0')])\n",
        "\n",
        "# %load_ext tensorboard\n",
        "# %tensorboard --logdir=tensorflow_hub\n",
        "\n",
        "# # Assigning Multiple callbacks\n",
        "# model_history = model.fit(x_train, y_train, epochs=5, ...,\n",
        "#                          callbacks=[create_model_checkpoint_callback(dir_name='tensorflow_hub', experimodelB0'),\n",
        "#                          create_tensorboard_callback(dir_name='tensorflow_hub', experimodelB0')])\n",
        "#\n",
        "# # OR\n",
        "#\n",
        "# callback_list = [create_early_stopping_callback(), create_model_checkpoint_callback(dir_name='tensorflow_hub', experimodelB0'), create_tensorboard_callback(dir_name='tensorflow_hub', experimodelB0')]\n",
        "# model_history = model.fit(x_train, y_train, epochs=5, ..., callbacks=callback_list)"
      ],
      "metadata": {
        "id": "Aoby52fuQvEf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Early Stopping callback"
      ],
      "metadata": {
        "id": "6Auh9Kzf-FFT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def create_early_stopping_callback(patience=10, verbose=1):\n",
        "  # Create a EarlyStopping callback that stops the training process when the validation loss stops improving\n",
        "  early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
        "                                                         # min_delta: Minimum change in the monitored quantity to qualify as an improvement,\n",
        "                                                         # i.e. an absolute change of less than min_delta, will count as no improvement.\n",
        "                                                         min_delta=0.01,\n",
        "                                                         # patience: Number of epochs with no improvement after which training will be stopped.\n",
        "                                                         patience=patience,\n",
        "                                                         mode='auto'\n",
        "                                                         # restore_best_weights: Whether to restore model weights from the epoch with the best\n",
        "                                                         # value of the monitored quantity. If False, the model weights obtained at the last\n",
        "                                                         # step of training are used. An epoch will be restored regardless of the performance\n",
        "                                                         # relative to the baseline. If no epoch improves on baseline, training will run for\n",
        "                                                         # patience epochs and restore weights from the best epoch in that set.\n",
        "                                                         restore_best_weights=True,\n",
        "                                                         verbose=verbose)\n",
        "\n",
        "  return early_stopping_callback\n",
        "\n",
        "# # Example usage\n",
        "# model_history = model.fit(x_train, y_train, epochs=5, ...,\n",
        "#                          callbacks=[create_early_stopping_callback()])\n",
        "\n",
        "# # Assigning Multiple callbacks\n",
        "# model_history = model.fit(x_train, y_train, epochs=5, ...,\n",
        "#                          callbacks=[create_model_checkpoint_callback(dir_name='tensorflow_hub', experimodelB0'),\n",
        "#                          create_early_stopping_callback()])\n",
        "#\n",
        "# # OR\n",
        "#\n",
        "# callback_list = [create_early_stopping_callback(), create_model_checkpoint_callback(dir_name='tensorflow_hub', experimodelB0'), create_tensorboard_callback(dir_name='tensorflow_hub', experimodelB0')]\n",
        "# model_history = model.fit(x_train, y_train, epochs=5, ..., callbacks=callback_list)\n",
        "\n",
        "# # Alternatives\n",
        "# earlystopping = callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=5, restore_best_weights=True, verbose=2)\n",
        "# earlystopping = callbacks.EarlyStopping(monitor='val_accuracy', mode='max', patience=5, restore_best_weights=True, verbose=2)"
      ],
      "metadata": {
        "id": "w1KPHbuR-DvZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Normalising and Standardising\n",
        "\n",
        "Feature normalization (or data standardization) of the explanatory (or predictor) variables is a technique used to center and normalise the data by subtracting the mean and dividing by the variance. If you take the mean and variance of the whole dataset you'll be introducing future information into the training explanatory variables.\n",
        "Therefore, you should perform feature normalisation over the training data. Then perform normalisation on testing instances as well, but this time using the mean and variance of training explanatory variables. In this way, we can test and evaluate whether our model can generalize well to new, unseen data points.\n",
        "\n",
        "[[Giorgos Myrianthous](https://stackoverflow.com/users/7131757/giorgos-myrianthous)]"
      ],
      "metadata": {
        "id": "E2ZUjUMfC8Gf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import Normalizer, MinMaxScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "'''\n",
        "Normalize and Scale data\n",
        "Fit only the Training data, transform training, validation and test data\n",
        "'''\n",
        "\n",
        "# Configure the pipeline\n",
        "pipeline = Pipeline([('normalizer', Normalizer()),\n",
        "                     ('scaler', MinMaxScaler())])\n",
        "\n",
        "# get normalization parameters by fitting to the training data\n",
        "pipeline.fit(X_train)\n",
        "\n",
        "# transform the training and validation data with these parameters\n",
        "X_train_transformed = pipeline.transform(X_train)\n",
        "# X_validate_transformed = pipeline.transform(X_validate)"
      ],
      "metadata": {
        "id": "c9VqQ9Zo_X5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modified Z-score method (Outlier Detection Method)\n",
        "\n",
        "We could also use a modified Z-score using the **Median Absolute Deviation** to define outliers on our reconstruction data.\n",
        "We would consider points to be outliers based on how much they deviate from the mean value; However, the mean is not a robust statistic; It is heavily influenced by outliers, meaning that the outliers we are trying to detect would affect the method itself.\n",
        "\n",
        "Mi = (0.6745 * (Xi - X)) / MAD\n",
        "\n",
        "MAD (Mean Absolute Deviation) = median(|Xi - X|)\n",
        "\n",
        "X is the median of the data\n",
        "\n",
        "Xi is the data points\n",
        "\n",
        "0.6745 is the 0.75th quartile of the standard normal distribution\n",
        "\n",
        "This scaling factor is used to convert the MAD into an estimate of the standard deviation of the underlying population assuming normality.\n",
        "\n",
        "https://www.itl.nist.gov/div898/handbook/eda/section3/eda356.htm#MAD\n",
        "\n",
        "https://www.itl.nist.gov/div898/handbook/eda/section3/eda35h.htm\n",
        "\n",
        "https://medium.com/@joaopedroferrazrodrigues/outliers-make-us-go-mad-univariate-outlier-detection-b3a72f1ea8c7"
      ],
      "metadata": {
        "id": "0Nu_gEUFE_ki"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "THRESHOLD = 3\n",
        "\n",
        "def mad_score(points):\n",
        "    m = np.median(points)\n",
        "    ad = np.abs(points - m)\n",
        "    mad = np.median(ad)\n",
        "    return 0.6745 * ad / mad\n",
        "\n",
        "# # Example usage - Calculate MSE (mean squared error) between ground truth and reconstructed data before employing mad_score\n",
        "# z_scores = mad_score(mse)\n",
        "# outliers = z_scores > THRESHOLD"
      ],
      "metadata": {
        "id": "Pm0yOp8ZFAaU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MAE (Mean Absolute Error) Loss"
      ],
      "metadata": {
        "id": "DtP7RcLVdKaL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mae_loss(x_true, x_pred):   # OR x_true, x_recons\n",
        "  mae_loss = np.mean(np.abs(x_pred - x_true), axis=1)\n",
        "  return mae_loss"
      ],
      "metadata": {
        "id": "uCdngyo7dPXv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SSIM Loss\n",
        "\n",
        "SSIM measures Structural Similarity between two images in terms of luminance, contrast, and structure. A value of 1 for SSIM indicates identical images. You want the SSIM loss function to be a minimum when training the autoencoder on good images.\n",
        "\n",
        "![](https://vicuesoft.com/glossary/ssim-ms-ssim.png)\n",
        "\n",
        "The SSIM index is a development of traditional methods such as PSNR (peak signal-to-noise ratio) and the MSE method, which turned out to be incompatible with the physiology of human perception. The difference with other techniques such as MSE or PSNR is that these approaches estimate absolute errors. Structural information is the idea that the pixels have strong inter-dependencies especially when they are spatially close. These dependencies carry important information about the structure of the objects in the visual scene.\n",
        "\n",
        "The SSIM index is calculated on various windows of an image. The above formula is applicable only for the brightness of the image, which is used to assess the quality. The resulting SSIM index ranges from -1 to +1. A value of +1 is achieved only with the complete authenticity of the samples. Typically, the metric is calculated for an 8 x 8 pixel window. The window can be displaced by a pixel, but experts recommend using groups of windows to reduce the complexity of the calculations.\n",
        "\n",
        "A more advanced form of SSIM, called **Multiscale SSIM (MS-SSIM)**, is performed at multiple scales through a multi-step downsampling process, reminiscent of multiscale processing in the early visual system. It has been shown to perform equally well or better than SSIM with various databases of subjective images and videos."
      ],
      "metadata": {
        "id": "RjkNTZE-Z9xw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def SSIMLoss(y_true, y_pred):\n",
        "  return 1 - tf.reduce_mean(tf.image.ssim(y_true, y_pred, 1.0))\n",
        "\n",
        "# Example Usage\n",
        "# model.compile(optimizer=optimizer, loss=SSIMLoss)"
      ],
      "metadata": {
        "id": "3OYM8sAqaBYo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save custom Model"
      ],
      "metadata": {
        "id": "S4IYn2sr_Yyw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "\n",
        "def save_custom_model(model, name=\"model\", verbose=1):\n",
        "    # Get Datetime object containing current date and time\n",
        "    date = str(datetime.now())\n",
        "    date = (((date.replace(\"-\", \"_\")).replace(\":\", \"_\")).replace(\" \", \"_\")).split(\".\")[0]\n",
        "\n",
        "    model_name = str(name) + str(date) + \".keras\"\n",
        "    model.save(model_name)\n",
        "\n",
        "    if verbose > 0:\n",
        "        print(f\"{model_name} was saved successfully\")\n",
        "\n",
        "\n",
        "# # Example Usage\n",
        "# save_custom_model(model, \"custom_model\")\n",
        "# # Loading the model back\n",
        "# loaded_model = keras.models.load_model('/path/to/custom_model_2023_08_16_06_45_05.keras')"
      ],
      "metadata": {
        "id": "mS1GjCgP_Xxx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TSNE Anomaly Scatter\n",
        "\n",
        "**Visualising clusters with t-SNE**\n",
        "\n",
        "t-Distributed Stochastic Neighbor Embedding (t-SNE) is a dimensionality reduction technique used for visualisations of complex datasets. It maps clusters in high-dimensional data to a two- or three dimensional plane so we can get an idea of how easy it will be to discriminate between classes. It does this by trying to keep the distance between data points in lower dimensions proportional to the probability that these data points are neighbours in the higher dimensions.\n"
      ],
      "metadata": {
        "id": "efCCI15gBMfF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def tsne_anomaly_scatter(features, labels, dimensions=2, save_as='graph.png'):\n",
        "    if dimensions not in (2, 3):\n",
        "        raise ValueError('Make sure that your dimension is 2d or 3d')\n",
        "\n",
        "    # t-SNE dimensionality reduction\n",
        "    features_embedded = TSNE(n_components=dimensions, random_state=RANDOM_SEED).fit_transform(features)\n",
        "\n",
        "    # initialising the plot\n",
        "    fig, ax = plt.subplots(figsize=(8,8))\n",
        "\n",
        "    # counting dimensions\n",
        "    if dimensions == 3: ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "    # Scattering map for Anomaly samples\n",
        "    ax.scatter(\n",
        "        *zip(*features_embedded[np.where(labels==1)]),\n",
        "        marker='o',\n",
        "        color='r',\n",
        "        s=2,\n",
        "        alpha=0.7,\n",
        "        label='Fraud'\n",
        "    )\n",
        "\n",
        "    # Scattering map for Normal samples\n",
        "    ax.scatter(\n",
        "        *zip(*features_embedded[np.where(labels==0)]),\n",
        "        marker='o',\n",
        "        color='g',\n",
        "        s=2,\n",
        "        alpha=0.3,\n",
        "        label='Clean'\n",
        "    )\n",
        "\n",
        "    # storing it to be displayed later\n",
        "    plt.legend(loc='best')\n",
        "    plt.savefig(save_as)\n",
        "    plt.show()\n",
        "\n",
        "# Example Usage\n",
        "# tsne_scatter(features, labels, dimensions=2, save_as='tsne_2d.png')"
      ],
      "metadata": {
        "id": "47GMPMx1_XvL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualize Triplet Images from the batches"
      ],
      "metadata": {
        "id": "veUrh52-eP_2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show_triplet_images(anchor, positive, negative, size=(10,10), row=3):\n",
        "  '''Visualize triplets from the batches'''\n",
        "  def plot_img(ax, image):\n",
        "    ax.imshow(image)\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "  fig = plt.figure(figsize=size)\n",
        "\n",
        "  axs = fig.subplots(row, 3)\n",
        "  for i in range(row):\n",
        "    plot_img(axs[i, 0], anchor[i])\n",
        "    plot_img(axs[i, 1], positive[i])\n",
        "    plot_img(axs[i, 2], negative[i])"
      ],
      "metadata": {
        "id": "Y0lbj6vHeUtf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Print Classification Report - Classification Evaluation Method"
      ],
      "metadata": {
        "id": "6mmzQ6fxgHK_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score # Evaluation metrics\n",
        "from sklearn.metrics import classification_report  # Precision, recall, f1-score metrics\n",
        "\n",
        "def print_eval_parameters(model, y_test, y_pred, labels):\n",
        "  '''This methods prints all evaluation parameters for classification models'''\n",
        "  print(\"====== \" + type(model).__name__ +\" model Evaluation metrics ======\")\n",
        "  print(\"Accuracy of model:      {:.3f}\".format(accuracy_score(y_test, y_pred)))                    # Accuracy score: (tp + tn) / (tp + fp + tn + fn)\n",
        "  print(\"Recall of model:        {:.3f}\".format(recall_score(y_test, y_pred, average=\"micro\")))     # Recall score: tp / (tp + fn)\n",
        "  print(\"Precision of model:     {:.3f}\".format(precision_score(y_test, y_pred, average=\"micro\")))  # Precision score: tp / (tp + fp)\n",
        "  print(\"F1 score of model:      {:.3f}\".format(f1_score(y_test, y_pred, average=\"micro\")))         # F1 score: 2 * (precision * recall) / (precision + recall)\n",
        "  # print(\"Mean accuracy of the model (Score):  {:.3f}\".format(model.score(X_train_valid_scl, y_train_valid)))  # Print model Mean Accuracy (score)\n",
        "  print(\"Misclassification Number: \", (y_test != y_pred).sum())\n",
        "  print(\"\\n====== \" + type(model).__name__ +\" model Detailed Classification Report ======\")\n",
        "  # Print K Nearest Neighbor model's classification report for validation set\n",
        "  # Report contains; Precision, recal and F1 score values for each label and\n",
        "  # model's accuracy, macro and weighted average\n",
        "  print(classification_report(y_test, y_pred, target_names=labels))"
      ],
      "metadata": {
        "id": "vyTyqAtTgUIQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot Accuracy and Loss Curves from Model History - Training and Validation"
      ],
      "metadata": {
        "id": "XH4OlLNFGFf8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Plot the validation and training data separately\n",
        "def plot_loss_curves(history, all_in_one=False):\n",
        "  \"\"\"\n",
        "  Returns separate loss curves for training and validation metrics.\n",
        "  \"\"\"\n",
        "  # <AxesSubplot:>\n",
        "  if all_in_one == True:  # Plots 'loss', 'accuracy', 'val_loss', 'val_accuracy' in the same graph\n",
        "    pd.DataFrame(cnn_model_history.history).plot(figsize=(10, 7))\n",
        "  else:\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "\n",
        "    accuracy = history.history['accuracy']\n",
        "    val_accuracy = history.history['val_accuracy']\n",
        "\n",
        "    epochs = range(len(history.history['loss']))\n",
        "\n",
        "    # Plot loss\n",
        "    plt.plot(epochs, loss, label='training_loss')\n",
        "    plt.plot(epochs, val_loss, label='val_loss')\n",
        "    plt.title('Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot accuracy\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, accuracy, label='training_accuracy')\n",
        "    plt.plot(epochs, val_accuracy, label='val_accuracy')\n",
        "    plt.title('Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.legend();\n",
        "\n",
        "# Example Usage - Train a model: model_hist = model.fit(x_train, y_train, epochs=...)\n",
        "# plot_loss_curves(model_history)"
      ],
      "metadata": {
        "id": "xitaOiZJ_Xsj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model History Comparison (especially after Fine-tuning processes)"
      ],
      "metadata": {
        "id": "bpJTmTWDVZiK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_historys(base_model_history, fine_tune_model_history, initial_epochs=5):\n",
        "    \"\"\"\n",
        "    Compares two model history objects.\n",
        "    \"\"\"\n",
        "    # Get base_model history measurements\n",
        "    acc = base_model_history.history[\"accuracy\"]\n",
        "    loss = base_model_history.history[\"loss\"]\n",
        "\n",
        "    print(len(acc))\n",
        "\n",
        "    val_acc = base_model_history.history[\"val_accuracy\"]\n",
        "    val_loss = base_model_history.history[\"val_loss\"]\n",
        "\n",
        "    # Combine base_model history with fine_tune_model_history\n",
        "    total_acc = acc + fine_tune_model_history.history[\"accuracy\"]\n",
        "    total_loss = loss + fine_tune_model_history.history[\"loss\"]\n",
        "\n",
        "    total_val_acc = val_acc + fine_tune_model_history.history[\"val_accuracy\"]\n",
        "    total_val_loss = val_loss + fine_tune_model_history.history[\"val_loss\"]\n",
        "\n",
        "    print(len(total_acc))\n",
        "    print(total_acc)\n",
        "\n",
        "    # Make plots\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    plt.subplot(2, 1, 1)\n",
        "    plt.plot(total_acc, label='Training Accuracy')\n",
        "    plt.plot(total_val_acc, label='Validation Accuracy')\n",
        "    plt.plot([initial_epochs-1, initial_epochs-1],\n",
        "              plt.ylim(), label='Start Fine Tuning') # reshift plot around epochs\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "\n",
        "    plt.subplot(2, 1, 2)\n",
        "    plt.plot(total_loss, label='Training Loss')\n",
        "    plt.plot(total_val_loss, label='Validation Loss')\n",
        "    plt.plot([initial_epochs-1, initial_epochs-1],\n",
        "              plt.ylim(), label='Start Fine Tuning') # reshift plot around epochs\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "lgKWKWQvVY0z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Show Confusion Matrix - Classification Evaluation Method"
      ],
      "metadata": {
        "id": "19epFzlZYTGJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def show_confusion_matrix(y_true, y_pred, classes=None, figsize=(10, 10), text_size=15, norm=False, savefig=False, fig_name='confusion_matrix'):\n",
        "  \"\"\"Makes a labelled confusion matrix comparing predictions and ground truth labels.\n",
        "\n",
        "  If classes is passed, confusion matrix will be labelled, if not, integer class values\n",
        "  will be used.\n",
        "\n",
        "  Args:\n",
        "    y_true: Array of truth labels (must be same shape as y_pred).\n",
        "    y_pred: Array of predicted labels (must be same shape as y_true).\n",
        "    classes: Array of class labels (e.g. string form). If `None`, integer labels are used.\n",
        "    figsize: Size of output figure (default=(10, 10)).\n",
        "    text_size: Size of output figure text (default=15).\n",
        "    norm: normalize values or not (default=False).\n",
        "    savefig: save confusion matrix to file (default=False).\n",
        "\n",
        "  Returns:\n",
        "    A labelled confusion matrix plot comparing y_true and y_pred.\n",
        "\n",
        "  Example usage:\n",
        "    make_confusion_matrix(y_true=test_labels, # ground truth test labels\n",
        "                          y_pred=y_preds, # predicted labels\n",
        "                          classes=class_names, # array of class label names\n",
        "                          figsize=(15, 15),\n",
        "                          text_size=10)\n",
        "  \"\"\"\n",
        "  # Create the confustion matrix\n",
        "  cm = confusion_matrix(y_true, y_pred)\n",
        "  cm_norm = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis] # normalize it\n",
        "  '''\n",
        "  >> A = np.array([2,0,1,8])\n",
        "  >> A.shape\n",
        "  Output: (4,)\n",
        "\n",
        "  >> A[np.newaxis, :]\n",
        "  Output: array([[2,0,1,8]])\n",
        "\n",
        "  >> A[:, np.newaxis]\n",
        "  Output: array([[2],\n",
        "                 [0],\n",
        "                 [1],\n",
        "                 [8]]\n",
        "  )\n",
        "  '''\n",
        "  n_classes = cm.shape[0] # find the number of classes we're dealing with\n",
        "\n",
        "  # Plot the figure and make it pretty\n",
        "  fig, ax = plt.subplots(figsize=figsize)\n",
        "  cax = ax.matshow(cm, cmap=plt.cm.Blues) # colors will represent how 'correct' a class is, darker == better\n",
        "  fig.colorbar(cax)\n",
        "\n",
        "  # Are there a list of classes?\n",
        "  if classes:\n",
        "    labels = classes\n",
        "  else:\n",
        "    labels = np.arange(cm.shape[0])\n",
        "\n",
        "  # Label the axes\n",
        "  ax.set(title=\"Confusion Matrix\",\n",
        "         xlabel=\"Predicted label\",\n",
        "         ylabel=\"True label\",\n",
        "         xticks=np.arange(n_classes), # create enough axis slots for each class\n",
        "         yticks=np.arange(n_classes),\n",
        "         xticklabels=labels, # axes will labeled with class names (if they exist) or ints\n",
        "         yticklabels=labels)\n",
        "\n",
        "  # Make x-axis labels appear on bottom\n",
        "  ax.xaxis.set_label_position(\"bottom\")\n",
        "  ax.xaxis.tick_bottom()\n",
        "\n",
        "  # Added: Rotate xticks for readability & increase font size (required due to such a large confusion matrix)\n",
        "  plt.xticks(rotation=70, fontsize=text_size)\n",
        "  plt.yticks(fontsize=text_size)\n",
        "\n",
        "  # Set the threshold for different colors\n",
        "  threshold = (cm.max() + cm.min()) / 2.\n",
        "\n",
        "  # Plot the text on each cell\n",
        "  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "    if norm:\n",
        "      plt.text(j, i, f\"{cm[i, j]} ({cm_norm[i, j]*100:.1f}%)\",\n",
        "              horizontalalignment=\"center\",\n",
        "              color=\"white\" if cm[i, j] > threshold else \"black\",\n",
        "              size=text_size)\n",
        "    else:\n",
        "      plt.text(j, i, f\"{cm[i, j]}\",\n",
        "              horizontalalignment=\"center\",\n",
        "              color=\"white\" if cm[i, j] > threshold else \"black\",\n",
        "              size=text_size)\n",
        "\n",
        "  # Save the figure to the current working directory\n",
        "  if savefig:\n",
        "    fig_name = fig_name + '.png'\n",
        "    fig.savefig(fig_name)"
      ],
      "metadata": {
        "id": "y_tialHyXswB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Show Confusion Matrix - Classification Evaluation Method (Alternative - 2)"
      ],
      "metadata": {
        "id": "tuFPPuTIhRlt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay  # Classifier Confusion Matrix visualization\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def show_confusion_matrix(y_test, y_pred, labels, w_h=(12, 7)):\n",
        "  '''This method plots Confusion matrix for classification models with given test dataset and prediction result array'''\n",
        "  confMatrix = confusion_matrix(y_test, y_pred)\n",
        "  dispConfMatrix = ConfusionMatrixDisplay(confMatrix, display_labels=labels)\n",
        "  dispConfMatrix.plot()\n",
        "  fig = plt.gcf()\n",
        "  w, h = w_h\n",
        "  fig.set_size_inches(w, h)"
      ],
      "metadata": {
        "id": "_gFQd9ZThUiM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot Randomly Image Predictions"
      ],
      "metadata": {
        "id": "uHKTVAbRkVYL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_randomly_img_predictions(img_arr, y_test, y_pred, labels, num_item=2, fig_size=[20,10]):\n",
        "  plt.figure(figsize=fig_size)\n",
        "  for img in range(num_item):\n",
        "      ix = rnd.randint(0, len(img_arr)-1)\n",
        "      display = plt.subplot(1, num_item, img+1)\n",
        "\n",
        "  plt.imshow(img_arr[ix], cmap=\"gray\")\n",
        "  act  = \"Act: \" + str(labels[(int(y_test[ix]))])\n",
        "  pred = \"Pred: \" + str(labels[(int(y_pred[ix]))])\n",
        "\n",
        "  plt.yticks([])\n",
        "  plt.title(act)\n",
        "  plt.ylabel(pred)\n",
        "\n",
        "  display.get_xaxis().set_visible(False)\n",
        "  #display.get_yaxis().set_visible(False)\n",
        "\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "uapDhwmykM-E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Show ROC Curve - Calculate AUC score"
      ],
      "metadata": {
        "id": "JlPa91J3hwOE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import auc\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "\n",
        "def show_ROC_score(self, y_test, pos_prob, kind='fp_tp', plot=False, label='Custom Classifier'):\n",
        "  if kind == 'fp_tp':   # False Positive-True Positive Curve\n",
        "    auc_score = roc_auc_score(y_test, pos_prob)\n",
        "    fp_rate, tp_rate, thresholds = roc_curve(y_test, pos_prob)\n",
        "    plt_x, plt_y, lbl_x, lbl_y = fp_rate, tp_rate, \"False Positive Rate (FP)\", \"True Positive Rate (TP)\"\n",
        "    # Generate a no skill prediction\n",
        "    noskill_probs = [0 for _ in range(len(y_test))]\n",
        "    ns_auc_score = roc_auc_score(y_test, noskill_probs)\n",
        "    noskill_fp_rate, noskill_tp_rate, noskill_thresholds = roc_curve(y_test, noskill_probs)\n",
        "\n",
        "  elif kind == 'pre_rec':   # Precision-Recall Curve\n",
        "    precision, recall, thresholds = precision_recall_curve(y_test, pos_prob)\n",
        "    auc_score = auc(recall, precision)\n",
        "    plt_x, plt_y, lbl_x, lbl_y = recall, precision, \"Recall\", \"Precision\"\n",
        "  else:\n",
        "    raise ValueError(\"Use 'fp_tp' or 'pre_rec' as kind parameter\")\n",
        "\n",
        "  print(\"AUC: \", auc_score)\n",
        "  if kind == 'fp_tp':\n",
        "    print(\"No-skill AUC: \", ns_auc_score)\n",
        "  print(\"\")\n",
        "\n",
        "  if plot == True:\n",
        "    plt.title(\"ROC Curve\")\n",
        "    plt.plot(plt_x, plt_y, marker='.', label=label)\n",
        "    if kind == 'fp_tp':\n",
        "      plt.plot(noskill_fp_rate, noskill_tp_rate, linestyle='--', label='No Skill Classifer')\n",
        "    plt.xlabel(lbl_x)\n",
        "    plt.ylabel(lbl_y)\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "F4S78JGXhv2-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualize Models"
      ],
      "metadata": {
        "id": "ejcYQ5OKOM5z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Block-wise model architecture visualization for Convolutional Networks"
      ],
      "metadata": {
        "id": "EioQQ6ZbPZds"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install visualkeras  # Install visualkeras package if requirements are not satisfied\n",
        "\n",
        "import visualkeras\n",
        "\n",
        "visualkeras.layered_view(model\n",
        "                         ,legend=True\n",
        "                         #,draw_volume=False\n",
        "                         #,spacing=30\n",
        "                         )"
      ],
      "metadata": {
        "id": "f9qJDjvIGiT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Flow chart based model architecture drawing"
      ],
      "metadata": {
        "id": "pgvGs8KmPTyk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils.vis_utils import plot_model\n",
        "\n",
        "plot_model(model,\n",
        "           to_file='model_plot.png',\n",
        "           show_shapes=True,\n",
        "           rankdir='LR'  # 'BT': Bottom to Top, 'TB': Top to Bottom, 'RL': Right to Left, 'LR': Left to Right\n",
        "           show_layer_names=True)"
      ],
      "metadata": {
        "id": "bjo3a_ZMOvtl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reference\n",
        "\n",
        "https://github.com/mrdbourke/tensorflow-deep-learning/tree/main\n",
        "\n",
        "https://www.kaggle.com/code/robinteuwens/anomaly-detection-with-auto-encoders#Unsupervised-Learning-with-Auto-Encoders\n",
        "\n",
        "https://pyimagesearch.com/2020/03/02/anomaly-detection-with-keras-tensorflow-and-deep-learning/\n",
        "\n",
        "https://www.kaggle.com/code/matheusfacure/semi-supervised-anomaly-detection-survey\n",
        "\n",
        "https://medium.com/analytics-vidhya/image-anomaly-detection-using-autoencoders-ae937c7fd2d1\n",
        "\n",
        "https://lilianweng.github.io/posts/2018-08-12-vae/"
      ],
      "metadata": {
        "id": "q-TZ6NQvSAMm"
      }
    }
  ]
}