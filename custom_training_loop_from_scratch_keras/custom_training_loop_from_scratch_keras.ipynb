{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Writing custom Training loops from scratch with Keras\n",
        "\n",
        "\n",
        "Reference: [Writing a training loop from scratch](https://www.tensorflow.org/guide/keras/writing_a_training_loop_from_scratch)"
      ],
      "metadata": {
        "id": "Co2Fabf_si7G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "8A0KcoqvsSEu"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import layers\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calling a model inside a `GradientTape` scope enables you to retrieve the gradients of the `trainable weights` of the layer with respect to a loss value. Using an `optimizer` instance, you can use these gradients to `update` these `variables` (which you can retrieve using `model.trainable_weights`).\n",
        "\n"
      ],
      "metadata": {
        "id": "4NH5MJP3ss_8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "EPOCHS = 2\n",
        "LEARNING_RATE = 1e-3"
      ],
      "metadata": {
        "id": "j4fu7GpltbyG"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create basic Model\n",
        "def get_basic_model():\n",
        "    inputs = keras.Input(shape=(784,), name=\"digits\")\n",
        "    x1 = layers.Dense(64, activation=\"relu\")(inputs)\n",
        "    x2 = layers.Dense(64, activation=\"relu\")(x1)\n",
        "    outputs = layers.Dense(10, name=\"predictions\")(x2)\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "    model.summary()\n",
        "    return model"
      ],
      "metadata": {
        "id": "r2Pd6afMsa95"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "basic_model = get_basic_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N87-_EPHtUsY",
        "outputId": "5a4bd89d-72fb-4f5e-c62d-996993c08586"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " digits (InputLayer)         [(None, 784)]             0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 64)                50240     \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " predictions (Dense)         (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 55050 (215.04 KB)\n",
            "Trainable params: 55050 (215.04 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate an optimizer.\n",
        "optimizer = keras.optimizers.SGD(learning_rate=LEARNING_RATE)\n",
        "# Instantiate a loss function.\n",
        "loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
      ],
      "metadata": {
        "id": "9xaDLB-BtX-X"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load and Prepare Dataset"
      ],
      "metadata": {
        "id": "9iZucOeNtlRR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "x_train = np.reshape(x_train, (-1, 784))\n",
        "x_test = np.reshape(x_test, (-1, 784))\n",
        "\n",
        "# Reserve 10000 samples for validation\n",
        "x_val = x_train[-10000:]\n",
        "y_val = y_train[-10000:]\n",
        "x_train = x_train[:-10000]\n",
        "y_train = y_train[:-10000]\n",
        "\n",
        "# Prepare the training dataset.\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(BATCH_SIZE)\n",
        "\n",
        "# Prepare the validation dataset.\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
        "val_dataset = val_dataset.batch(BATCH_SIZE)"
      ],
      "metadata": {
        "id": "Tnf-gFojtkDt"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Loop\n",
        "\n",
        "* We open a for loop that iterates over epochs\n",
        "* For each epoch, we open a for loop that iterates over the dataset, in batches"
      ],
      "metadata": {
        "id": "9qZ-i1Kst3fD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    print(\"\\nStart of epoch %d\" % (epoch,))\n",
        "\n",
        "    # Iterate over the batches of the dataset\n",
        "    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
        "        with tf.GradientTape() as tape:\n",
        "            ''' Run the forward pass of the layer.\n",
        "            The operations that the layer applies to its inputs are going to be\n",
        "            recorded on the GradientTape.'''\n",
        "            logits = basic_model(x_batch_train, training=True)  # ts for this minibatch\n",
        "            # Compute the loss\n",
        "            loss = loss_fn(y_batch_train, logits)\n",
        "\n",
        "        # Retrieve the gradients of the trainable variables with respect to the loss.\n",
        "        grads = tape.gradient(loss, basic_model.trainable_weights)\n",
        "        # Note that we used trainable_weights, not trainable_variables as used in train_step method of custom models.\n",
        "\n",
        "        # Run one step of gradient descent by updating the value of the variables\n",
        "        # to minimize the loss\n",
        "        optimizer.apply_gradients(zip(grads, basic_model.trainable_weights))\n",
        "\n",
        "        if step % 200 == 0:\n",
        "            print(\"Training Loss at step %d: %.4f\" % (step, float(loss)))\n",
        "            print(\"Seen so far: %s samples\" % ((step + 1) * BATCH_SIZE))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVTciTajtzs3",
        "outputId": "8ca749c0-8188-48af-93fd-78e9db7f5034"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Start of epoch 0\n",
            "Training Loss at step 0: 133.8576\n",
            "Seen so far: 64 samples\n",
            "Training Loss at step 200: 1.2480\n",
            "Seen so far: 12864 samples\n",
            "Training Loss at step 400: 0.7482\n",
            "Seen so far: 25664 samples\n",
            "Training Loss at step 600: 0.8331\n",
            "Seen so far: 38464 samples\n",
            "\n",
            "Start of epoch 1\n",
            "Training Loss at step 0: 1.2908\n",
            "Seen so far: 64 samples\n",
            "Training Loss at step 200: 0.8234\n",
            "Seen so far: 12864 samples\n",
            "Training Loss at step 400: 0.8052\n",
            "Seen so far: 25664 samples\n",
            "Training Loss at step 600: 0.7437\n",
            "Seen so far: 38464 samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Handling Metrics\n",
        "\n",
        "* Instantiate the metric at the start of the loop\n",
        "* Call `metric.update_state()` after each batch\n",
        "* Call `metric.result()` when you need to display the current value of the metric\n",
        "* Call `metric.reset_states()` when you need to clear the state of the metric (typically at the end of an epoch)"
      ],
      "metadata": {
        "id": "f88xD2HOJX1m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "basic_model_2 = get_basic_model()\n",
        "# Instantiate an optimizer to train the model.\n",
        "optimizer = keras.optimizers.SGD(learning_rate=1e-3)\n",
        "# Instantiate a loss function.\n",
        "loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAWjHNf4JXkU",
        "outputId": "698eb2dc-50ae-49fc-ac50-4615d4aeadc9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " digits (InputLayer)         [(None, 784)]             0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 64)                50240     \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " predictions (Dense)         (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 55050 (215.04 KB)\n",
            "Trainable params: 55050 (215.04 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prepare metrics"
      ],
      "metadata": {
        "id": "Qk6Ix_1qJznQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_acc_metric = keras.metrics.SparseCategoricalAccuracy()\n",
        "val_acc_metric = keras.metrics.SparseCategoricalAccuracy()"
      ],
      "metadata": {
        "id": "TlGLqCdCJDWj"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    print(\"\\nStart of epoch %d\" % (epoch,))\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Iterate over the batches of the dataset\n",
        "    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
        "        with tf.GradientTape() as tape:\n",
        "            ''' Run the forward pass of the layer.\n",
        "            The operations that the layer applies to its inputs are going to be\n",
        "            recorded on the GradientTape.'''\n",
        "            logits = basic_model_2(x_batch_train, training=True)  # ts for this minibatch\n",
        "            # Compute the loss\n",
        "            loss = loss_fn(y_batch_train, logits)\n",
        "\n",
        "        # Retrieve the gradients of the trainable variables with respect to the loss.\n",
        "        grads = tape.gradient(loss, basic_model_2.trainable_weights)\n",
        "        # Note that we used trainable_weights, not trainable_variables as used in train_step method of custom models.\n",
        "\n",
        "        # Run one step of gradient descent by updating the value of the variables\n",
        "        # to minimize the loss\n",
        "        optimizer.apply_gradients(zip(grads, basic_model_2.trainable_weights))\n",
        "\n",
        "        # Update training metric\n",
        "        train_acc_metric.update_state(y_batch_train, logits)\n",
        "\n",
        "        if step % 200 == 0:\n",
        "            print(\"Training Loss at step %d: %.4f\" % (step, float(loss)))\n",
        "            print(\"Seen so far: %s samples\" % ((step + 1) * BATCH_SIZE))\n",
        "\n",
        "    # Display metrics at the end of each epoch\n",
        "    train_acc = train_acc_metric.result()\n",
        "    print(\"Training Accuracy over %d.epoch: %.4f\" % (epoch, float(train_acc),))\n",
        "\n",
        "    # ==== Reset training metrics at the end of the each epoch ====\n",
        "    train_acc_metric.reset_states()\n",
        "\n",
        "    # Run a validation loop at the end of each epoch\n",
        "    for x_batch_val, y_batch_val in val_dataset:\n",
        "        val_logits = basic_model_2(x_batch_val, training=False)\n",
        "        # Update val metrics\n",
        "        val_acc_metric.update_state(y_batch_val, val_logits)\n",
        "\n",
        "    val_acc = val_acc_metric.result()\n",
        "    # ==== Reset training metrics at the end of the each epoch ====\n",
        "    val_acc_metric.reset_state()\n",
        "\n",
        "    print(\"Validation acc: %.4f\" % (float(val_acc),))\n",
        "    print(\"Time taken: %.2fs\" % (time.time() - start_time))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmGS3w0oJ-iL",
        "outputId": "34413cf0-4ed9-4b56-a270-9e7246814973"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Start of epoch 0\n",
            "Training Loss at step 0: 0.5148\n",
            "Seen so far: 64 samples\n",
            "Training Loss at step 200: 0.5658\n",
            "Seen so far: 12864 samples\n",
            "Training Loss at step 400: 0.4478\n",
            "Seen so far: 25664 samples\n",
            "Training Loss at step 600: 0.9974\n",
            "Seen so far: 38464 samples\n",
            "Training Accuracy over 0.epoch: 0.8645\n",
            "Validation acc: 0.8775\n",
            "Time taken: 21.73s\n",
            "\n",
            "Start of epoch 1\n",
            "Training Loss at step 0: 0.6932\n",
            "Seen so far: 64 samples\n",
            "Training Loss at step 200: 0.3110\n",
            "Seen so far: 12864 samples\n",
            "Training Loss at step 400: 0.5195\n",
            "Seen so far: 25664 samples\n",
            "Training Loss at step 600: 0.2024\n",
            "Seen so far: 38464 samples\n",
            "Training Accuracy over 1.epoch: 0.8946\n",
            "Validation acc: 0.9015\n",
            "Time taken: 22.21s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Speeding-up the training step with tf.function\n",
        "\n",
        "The default runtime in TensorFlow 2 is `eager execution`. As such, our training loop above executes eagerly.\n",
        "\n",
        "This is great for debugging, but `graph compilation` has a definite `performance` advantage. Describing your computation as a `static graph` enables the framework to apply `global performance optimizations`. This is impossible when the framework is constrained to greedily execute one operation after another, with no knowledge of what comes next.\n",
        "\n",
        "You can compile into a `static graph` any function that `takes tensors as input`. Just add a `@tf.function` decorator on it, like this:"
      ],
      "metadata": {
        "id": "Sg1j-wzZcSDN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def train_step(x, y):\n",
        "    with tf.GradientTape() as tape:\n",
        "        logits = basic_model_2(x, training=True)\n",
        "        loss = loss_fn(y, logits)\n",
        "    grads = tape.gradient(loss, basic_model_2.trainable_weights)\n",
        "    optimizer.apply_gradients(zip(grads, basic_model_2.trainable_weights))\n",
        "    train_acc_metric.update_state(y, logits)\n",
        "    return loss"
      ],
      "metadata": {
        "id": "yZtccPDqcZcu"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for evaluation step\n",
        "@tf.function\n",
        "def test_step(x, y):\n",
        "    val_logits = basic_model_2(x, training=False)\n",
        "    val_acc_metric.update_state(y, val_logits)"
      ],
      "metadata": {
        "id": "8s_CdJaBdsZD"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    print(\"\\nStart of epoch %d\" % (epoch,))\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Iterate over the batches of the dataset.\n",
        "    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
        "        # Train step\n",
        "        loss = train_step(x_batch_train, y_batch_train)\n",
        "\n",
        "        # Log every 200 batches.\n",
        "        if step % 200 == 0:\n",
        "            print(\n",
        "                \"Training loss (for one batch) at step %d: %.4f\"\n",
        "                % (step, float(loss))\n",
        "            )\n",
        "            print(\"Seen so far: %d samples\" % ((step + 1) * BATCH_SIZE))\n",
        "\n",
        "    # Display metrics at the end of each epoch.\n",
        "    train_acc = train_acc_metric.result()\n",
        "    print(\"Training acc over epoch: %.4f\" % (float(train_acc),))\n",
        "\n",
        "    # Reset training metrics at the end of each epoch\n",
        "    train_acc_metric.reset_states()\n",
        "\n",
        "    # Evaluation step\n",
        "    for x_batch_val, y_batch_val in val_dataset:\n",
        "        test_step(x_batch_val, y_batch_val)\n",
        "\n",
        "    val_acc = val_acc_metric.result()\n",
        "    val_acc_metric.reset_states()\n",
        "    print(\"Validation acc: %.4f\" % (float(val_acc),))\n",
        "    print(\"Time taken: %.2fs\" % (time.time() - start_time))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qFjpcjZd6_R",
        "outputId": "5167f72d-2594-423e-8efa-ee79006c4e97"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Start of epoch 0\n",
            "Training loss (for one batch) at step 0: 0.4023\n",
            "Seen so far: 64 samples\n",
            "Training loss (for one batch) at step 200: 0.7137\n",
            "Seen so far: 12864 samples\n",
            "Training loss (for one batch) at step 400: 0.1519\n",
            "Seen so far: 25664 samples\n",
            "Training loss (for one batch) at step 600: 0.3010\n",
            "Seen so far: 38464 samples\n",
            "Training acc over epoch: 0.9085\n",
            "Validation acc: 0.9124\n",
            "Time taken: 2.99s\n",
            "\n",
            "Start of epoch 1\n",
            "Training loss (for one batch) at step 0: 0.4876\n",
            "Seen so far: 64 samples\n",
            "Training loss (for one batch) at step 200: 0.2370\n",
            "Seen so far: 12864 samples\n",
            "Training loss (for one batch) at step 400: 0.1396\n",
            "Seen so far: 25664 samples\n",
            "Training loss (for one batch) at step 600: 0.1095\n",
            "Seen so far: 38464 samples\n",
            "Training acc over epoch: 0.9194\n",
            "Validation acc: 0.9136\n",
            "Time taken: 2.31s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Low-level handling of losses tracked by the model\n",
        "\n",
        "Layers & models recursively `track` any `losses` created `during` the `forward pass` by layers that call `self.add_loss(value)`. The resulting list of scalar loss values are available via the property model.losses at the end of the forward pass.\n",
        "\n",
        "If you want to be using these loss components, you should `sum` them and `add` them to the `main loss` in your training step.\n",
        "\n",
        "Consider this layer, that creates an activity regularization loss:"
      ],
      "metadata": {
        "id": "PjRZ5KQTeasU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@keras.saving.register_keras_serializable()\n",
        "class ActivityRegularizationLayer(layers.Layer):\n",
        "    def call(self, inputs):\n",
        "        self.add_loss(1e-2*tf.reduce_sum(inputs))\n",
        "        return inputs"
      ],
      "metadata": {
        "id": "OdaRLu43ePvZ"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build the basic model again with ActivityRegularizationLayer"
      ],
      "metadata": {
        "id": "Be5Vsz8TkJXb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_basic_model_with_activity_regularization_layer():\n",
        "    inputs = keras.Input(shape=(784,), name=\"digits\")\n",
        "    x = layers.Dense(64, activation=\"relu\")(inputs)\n",
        "    # Insert activity regularization as a layer\n",
        "    x = ActivityRegularizationLayer()(x)\n",
        "    x = layers.Dense(64, activation=\"relu\")(x)\n",
        "    outputs = layers.Dense(10, name=\"predictions\")(x)\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "    model.summary()\n",
        "    return model"
      ],
      "metadata": {
        "id": "9PlZO8aGkIF6"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_with_activity_regularization_layer = get_basic_model_with_activity_regularization_layer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i0LkK_eGkcjB",
        "outputId": "8fed4c69-b5c4-4f27-d176-8c7b894d1bdb"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " digits (InputLayer)         [(None, 784)]             0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 64)                50240     \n",
            "                                                                 \n",
            " activity_regularization_la  (None, 64)                0         \n",
            " yer (ActivityRegularizatio                                      \n",
            " nLayer)                                                         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " predictions (Dense)         (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 55050 (215.04 KB)\n",
            "Trainable params: 55050 (215.04 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training step with ActivityRegularizationLayer"
      ],
      "metadata": {
        "id": "GOr-iJ5Vkj6R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def train_step(x, y):\n",
        "    with tf.GradientTape() as tape:\n",
        "        logits = model_with_activity_regularization_layer(x, training=True)\n",
        "        loss_value = loss_fn(y, logits)\n",
        "\n",
        "        # Add any extra losses created during the forward pass.\n",
        "        loss_value += sum(model_with_activity_regularization_layer.losses)\n",
        "\n",
        "    grads = tape.gradient(loss_value, model_with_activity_regularization_layer.trainable_weights)\n",
        "    optimizer.apply_gradients(zip(grads, model_with_activity_regularization_layer.trainable_weights))\n",
        "    train_acc_metric.update_state(y, logits)\n",
        "\n",
        "    return loss_value"
      ],
      "metadata": {
        "id": "YXrzM1txkguE"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### End-to-end GAN (Generative adversarial networks) example with training loop from scratch\n",
        "\n",
        "A GAN training loop\n",
        "\n",
        "1. **Train the discriminator**. - Sample a `batch of random points` in the `latent space`. - Turn the points into `fake images` via the \"`generator`\" model. - Get a `batch of real images` and `combine` them `with` the `generated images`. - Train the \"discriminator\" model to `classify generated` vs. `real images`.\n",
        "\n",
        "2. **Train the generator**. - `Sample random points` in the `latent space`. - Turn the points into fake images via the \"generator\" network. - Get a `batch of real images` and `combine` them with the `generated images`. - Train the \"generator\" model to \"fool\" the discriminator and `classify` the `fake images as real`."
      ],
      "metadata": {
        "id": "TqAZkih9kxrH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "knFL448Xpedq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_SHAPE = (28, 28, 1)\n",
        "LATENT_DIM = 128"
      ],
      "metadata": {
        "id": "K4yheSaBmUCA"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_discriminator_model(input_shape):\n",
        "    discriminator = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=input_shape),\n",
        "        layers.Conv2D(64, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.Conv2D(128, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "        layers.LeakyReLU(alpha=0.2),\n",
        "        layers.GlobalMaxPooling2D(),\n",
        "        layers.Dense(1),\n",
        "    ],\n",
        "    name=\"discriminator\",\n",
        "    )\n",
        "    discriminator.summary()\n",
        "    return discriminator"
      ],
      "metadata": {
        "id": "Oo2q-0_kksgX"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_generator_model(latent_dim):\n",
        "    generator = keras.Sequential(\n",
        "        [\n",
        "            keras.Input(shape=(latent_dim,)),\n",
        "            # We want to generate 128 coefficients to reshape into a 7x7x128 map\n",
        "            layers.Dense(7 * 7 * 128),\n",
        "            layers.LeakyReLU(alpha=0.2),\n",
        "            layers.Reshape((7, 7, 128)),\n",
        "            layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
        "            layers.LeakyReLU(alpha=0.2),\n",
        "            layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
        "            layers.LeakyReLU(alpha=0.2),\n",
        "            layers.Conv2D(1, (7, 7), padding=\"same\", activation=\"sigmoid\"),\n",
        "        ],\n",
        "        name=\"generator\",\n",
        "    )\n",
        "    generator.summary()\n",
        "    return generator"
      ],
      "metadata": {
        "id": "BQueRtuEmV7C"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator_model = get_discriminator_model(INPUT_SHAPE)\n",
        "generator_model = get_generator_model(LATENT_DIM)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNz5-q9jmkV1",
        "outputId": "41062bb5-0634-48d0-d468-a8d9c8fe8394"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"discriminator\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 14, 14, 64)        640       \n",
            "                                                                 \n",
            " leaky_re_lu (LeakyReLU)     (None, 14, 14, 64)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 7, 7, 128)         73856     \n",
            "                                                                 \n",
            " leaky_re_lu_1 (LeakyReLU)   (None, 7, 7, 128)         0         \n",
            "                                                                 \n",
            " global_max_pooling2d (Glob  (None, 128)               0         \n",
            " alMaxPooling2D)                                                 \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 74625 (291.50 KB)\n",
            "Trainable params: 74625 (291.50 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Model: \"generator\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_11 (Dense)            (None, 6272)              809088    \n",
            "                                                                 \n",
            " leaky_re_lu_2 (LeakyReLU)   (None, 6272)              0         \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 7, 7, 128)         0         \n",
            "                                                                 \n",
            " conv2d_transpose (Conv2DTr  (None, 14, 14, 128)       262272    \n",
            " anspose)                                                        \n",
            "                                                                 \n",
            " leaky_re_lu_3 (LeakyReLU)   (None, 14, 14, 128)       0         \n",
            "                                                                 \n",
            " conv2d_transpose_1 (Conv2D  (None, 28, 28, 128)       262272    \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " leaky_re_lu_4 (LeakyReLU)   (None, 28, 28, 128)       0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 28, 28, 1)         6273      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1339905 (5.11 MB)\n",
            "Trainable params: 1339905 (5.11 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate one optimizer for the discriminator and another for the generator.\n",
        "d_optimizer = keras.optimizers.Adam(learning_rate=0.0003)\n",
        "g_optimizer = keras.optimizers.Adam(learning_rate=0.0004)\n",
        "\n",
        "# Instantiate a loss function.\n",
        "loss_fn = keras.losses.BinaryCrossentropy(from_logits=True)"
      ],
      "metadata": {
        "id": "6Q3sTdrxm2mo"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def train_step(real_images):\n",
        "    # Sample random points in the Latent space\n",
        "    random_latent_vectors = tf.random.normal(shape=(BATCH_SIZE, LATENT_DIM))\n",
        "\n",
        "    # Decode samples to fake images\n",
        "    generated_images = generator_model(random_latent_vectors)\n",
        "\n",
        "    # Combine generated images with real images\n",
        "    combined_images = tf.concat([generated_images, real_images], axis=0)\n",
        "\n",
        "    # Assemble labels discriminating real from fake images\n",
        "    labels = tf.concat(\n",
        "        [tf.ones((BATCH_SIZE, 1)), tf.zeros((real_images.shape[0], 1))], axis=0\n",
        "    )\n",
        "\n",
        "    # Add random noise to the labels !!!\n",
        "    labels += 0.05 * tf.random.uniform(labels.shape)\n",
        "\n",
        "    # Train the discriminator\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = discriminator_model(combined_images)\n",
        "        d_loss = loss_fn(labels, predictions)\n",
        "\n",
        "    grads = tape.gradient(d_loss, discriminator_model.trainable_weights)\n",
        "    d_optimizer.apply_gradients(zip(grads, discriminator_model.trainable_weights))\n",
        "\n",
        "    # Sample random points in the latent space as we did before\n",
        "    random_latent_vectors = tf.random.normal(shape=(BATCH_SIZE, LATENT_DIM))\n",
        "\n",
        "    # Assemble labels that say \"all real images\"\n",
        "    misleading_labels = tf.zeros((BATCH_SIZE, 1))\n",
        "\n",
        "    # Train the generator\n",
        "    # Do not update the weights of the discriminator\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = discriminator_model(generator_model(random_latent_vectors))  # Not combined images, only generated\n",
        "        g_loss = loss_fn(misleading_labels, predictions)\n",
        "\n",
        "    grads = tape.gradient(g_loss, generator_model.trainable_weights)\n",
        "    g_optimizer.apply_gradients(zip(grads, generator_model.trainable_weights))\n",
        "\n",
        "    return d_loss, g_loss, generated_images"
      ],
      "metadata": {
        "id": "-M3ebrz8m2dj"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load and Prepare Dataset"
      ],
      "metadata": {
        "id": "im2Df0lcqWKj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, _), (x_test, _) = keras.datasets.mnist.load_data()\n",
        "all_digits = np.concatenate([x_train, x_test])\n",
        "all_digits = all_digits.astype(\"float32\") / 255.0\n",
        "all_digits = np.reshape(all_digits, (-1, 28, 28, 1))\n",
        "dataset = tf.data.Dataset.from_tensor_slices(all_digits)\n",
        "dataset = dataset.shuffle(buffer_size=1024).batch(BATCH_SIZE)"
      ],
      "metadata": {
        "id": "SFp1uaq8m2ZT"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train the GAN model"
      ],
      "metadata": {
        "id": "p_hZSoNat-Xb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "save_dir = \"./\"\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    print(\"\\nStart epoch\", epoch)\n",
        "\n",
        "    for step, real_images in enumerate(dataset):\n",
        "        # Train one bacth of real images\n",
        "        d_loss, g_loss, generated_images = train_step(real_images)\n",
        "\n",
        "        if step % 200 == 0:\n",
        "            # Print metrics\n",
        "            print(\"Discriminator loss at step %d: %.2f\" % (step, d_loss))\n",
        "            print(\"Adversarial loss at step %d: %.2f\" % (step, g_loss))\n",
        "\n",
        "            # Save one generated image\n",
        "            img = keras.utils.array_to_img(generated_images[0] * 255.0, scale=False)\n",
        "            img.save(os.path.join(save_dir, \"generated_img\" + str(step) + \".png\"))\n",
        "\n",
        "        # To limit execution time we stop after 10 steps.\n",
        "        # Remove the lines below to actually train the model!\n",
        "        if step > 10:\n",
        "            break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_C-ej4cwm2Wr",
        "outputId": "cec2c328-4bfd-46b5-cf1e-01849a938819"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Start epoch 0\n",
            "Discriminator loss at step 0: 0.13\n",
            "Adversarial loss at step 0: 1.88\n",
            "\n",
            "Start epoch 1\n",
            "Discriminator loss at step 0: 0.10\n",
            "Adversarial loss at step 0: 2.28\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reference\n",
        "\n",
        "https://www.tensorflow.org/guide/keras/writing_a_training_loop_from_scratch"
      ],
      "metadata": {
        "id": "sIOFeo48uCJm"
      }
    }
  ]
}